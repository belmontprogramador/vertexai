const { sendBotMessage } = require("../../../messageSender");
const {
  setUserStage,
  appendToConversation,
  getConversation,
  getNomeUsuario,
} = require("../../../redisService");
const { agenteDeDemonstracaoDetalhada } = require("../agenteDeDemonstracaoDetalhada"); 
const { obje√ß√µesVertex } = require("../../../utils/documentacoes/objecoes");
const { gatilhosEmocionaisVertex } = require('../../../utils/documentacoes/gatilhosEmocionais');
const { tomDeVozVertex } = require('../../../utils/documentacoes/tomDeVozVertex'); 
const { getAllCelulares } = require('../../../dbService')
const { handlers: handlersDemonstracaoDetalhada } = require("../../../GerenciadorDeRotinas/GerenciadorDeDemonstracao/agenteDeDemonstracaoDetalhada");
const { agenteDeDemonstracaoPorNomePorValor } = require("../PorValor/agenteDeDemonstracaoPorNomePorValor");
const { sanitizarEntradaComQuoted } = require("../../../utils/utilitariosDeMensagem/sanitizarEntradaComQuoted");
const { prepararContextoDeModelosRecentesFluxo } = require("../../../utils/utilitariosDeMensagem/prepararContextoDeModelosRecentesFluxo");
const { rotinaDeBoleto } = require("../../../GerenciadorDeRotinas/GerenciadorDeDemonstracao/PorBoleto/rotinaDeBoleto");

const OpenAI = require("openai");
require("dotenv").config();
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const obterModelosDoBling = async () => {
  try {
    const celulares = await getAllCelulares();

    const termosIgnorados = [
      "BLACK", "WHITE", "BLUE", "GREEN", "GOLD", "PURPLE", "SILVER", "CORAL",
      "MIDNIGHT", "OCEAN", "TEAL", "AZUL", "VERDE", "LAVENDER", "VOYAGE",
      "MARBLE", "STORM", "LIGHTNING", "SPARKLE", "DARK", "LIME", "STAR", "STARRY",
      "OC√âANO", "ROM", "RAM"
    ];

    const normalizeNome = (nome) => nome
      .replace(/^smartphone\s*/i, "")
      .replace(/[^\w\s]/gi, '')
      .trim()
      .split(/\s+/)
      .filter(p => !termosIgnorados.includes(p.toUpperCase()))
      .join(" ")
      .toLowerCase()
      .trim();

    const mapaUnico = new Map();

    for (const c of celulares) {
      const chave = normalizeNome(c.nome);
      if (!mapaUnico.has(chave)) {
        mapaUnico.set(chave, {
          nome: c.nome,
          preco: c.preco,
          descricaoCurta: c.descricao,
          imagemURL: c.imageURL,
          precoParcelado: c.precoParcelado,
          fraseImpacto: c.fraseImpacto,
          subTitulo: c.subTitulo
        });
      }
    }

    const listaParaPrompt = Array.from(mapaUnico.values());

    console.log("üì¶ Modelos carregados do banco:");
    listaParaPrompt.forEach(m => console.log("-", m.nome));

    return listaParaPrompt;
  } catch (err) {
    console.error("‚ùå Erro ao carregar modelos do banco:", err);
    return [];
  }
};

const calcularSimilaridadePorEmbeddings = async (entrada, modelos) => {
  const entradaEmbedding = await openai.embeddings.create({
    model: "text-embedding-3-small",
    input: entrada
  });

  const nomesModelos = modelos.map(m => m.nome);

  const modelosEmbedding = await openai.embeddings.create({
    model: "text-embedding-3-small",
    input: nomesModelos
  });

  const vetorEntrada = entradaEmbedding.data[0].embedding;

  const distancias = modelosEmbedding.data.map((item, i) => {
    const modeloOriginal = modelos[i];
    const vetorModelo = item.embedding;
    const score = vetorEntrada.reduce((acc, val, idx) => acc + val * vetorModelo[idx], 0);
    return {
      imagemURL: modeloOriginal.imagemURL,
      descricaoCurta: modeloOriginal.descricaoCurta,
      modelo: modeloOriginal.nome,
      preco: modeloOriginal.preco,
      subTitulo: modeloOriginal.subTitulo,
      fraseImpacto: modeloOriginal.fraseImpacto,
      precoParcelado: modeloOriginal.precoParcelado,
      score
    };
  });

  return distancias.sort((a, b) => b.score - a.score);
};

const identificarModeloPorNomePosDemonstra√ß√£oPorValor = async ({ sender, msgContent, pushName, quotedMessage }) => {
  try {
    await setUserStage(sender, "identificar_modelo_por_nome_pos_demonstracao_por_valor");


    const entrada = await sanitizarEntradaComQuoted(sender, msgContent, quotedMessage);

    const { modelos, modelosConfirmados, nomeUsuario, conversaCompleta } = await prepararContextoDeModelosRecentesFluxo(sender);

    // üéØ Tenta detectar similaridade de entrada com algum modelo
    const listaModelos = await obterModelosDoBling();
    const similares = await calcularSimilaridadePorEmbeddings(entrada, listaModelos);
    const maisProvavel = similares?.[0];

    if (maisProvavel?.score > 0.90) {
      console.log("‚úÖ Entrada casa fortemente com modelo:", maisProvavel.modelo);
      await appendToConversation(sender, {
        tipo: "deliberacao_toa",
        conteudo: {
          acao: "demonstracaoDetalhada",
          motivo: `Cliente mencionou ${maisProvavel.modelo} com alta similaridade`,
          argumento: { modeloMencionado: maisProvavel.modelo }
        },
        timestamp: new Date().toISOString()
      });

      return await handlers.demonstracaoDetalhada(sender, {
        modeloMencionado: maisProvavel.modelo
      }, { msgContent: entrada });
    }

    // ü§ñ Delibera√ß√£o TOA
    const deliberarPossibilidades = async () => {
      const prompt = `
      üìú Hist√≥rico da conversa:
        ${conversaCompleta}
      
      üß† √öltima mensagem do cliente:
      "${entrada}"
      
      üì± Modelos apresentados:
      ${modelos.map(m => `‚û°Ô∏è *${m.nome}*\nüìù ${m.descricaoCurta}\nüíµ Pre√ßo: R$ ${m.preco.toFixed(2)}`).join("\n")}
      
      Nome do cliente: ${nomeUsuario}
      
      ‚úÖ Modelos confirmados anteriormente pelo cliente:
      ${modelosConfirmados.length > 0
          ? modelosConfirmados.map(m => `‚úîÔ∏è *${m}*`).join("\n")
          : "Nenhum ainda foi confirmado."}
      
      üß† √öltimo modelo confirmado:
      ${modelosConfirmados[modelosConfirmados.length - 1] || "nenhum"}
      
      üí° Quais s√£o as 3 possibilidades mais prov√°veis que o cliente quer com essa mensagem?
      
      1. **demonstracaoDetalhada** ‚Üí quando estiver decidido ou indicar desejo de finalizar, mesmo que sem palavras exatas como "fechou". Ex: ‚Äúgostei muito desse‚Äù, ‚Äúacho que vou a√≠ amanh√£‚Äù, ‚Äúvamos ver esse a√≠‚Äù.
      
      2. Se o cliente fizer QUALQUER pergunta sobre um modelo que ja tenha sido mencionado (mesmo sem ponto de interroga√ß√£o) ‚Äî como "√© bom?", "e esse?", "a c√¢mera √© boa?", "qual o pre√ßo?" ‚Äî **sobre qualquer um dos modelos apresentados anteriormente**, ou **sobre o √∫ltimo modelo confirmado**, interprete como d√∫vida ou indecis√£o. Escolha **responderDuvida**.
      
      ‚ö†Ô∏è Mesmo se o cliente mencionar o nome do modelo de novo ou compar√°-lo com outro lugar (ex: Mercado Livre), se esse modelo j√° foi apresentado, ainda assim escolha **responderDuvida**, pois o cliente j√° demonstrou interesse anteriormente.
      
      3. Se ele mencionar qualquer modelo que **ainda n√£o foi apresentado na conversa** e **tamb√©m n√£o √© o √∫ltimo confirmado**, qualquer tipo de men√ß√£o que seja, escolha **agenteDeDemonstracaoPorNomePorValor**. Isso indica que o cliente est√° abrindo uma nova inten√ß√£o.
      
      4. Se a mensagem do cliente **n√£o mencionar nenhum modelo**,  
e a d√∫vida parecer geral, filos√≥fica, comportamental ou fora do escopo dos modelos ‚Äî  
ex: "voc√™s vendem usados?", "e se der defeito?", "voc√™s tem loja f√≠sica?",  
"qual √© o diferencial de voc√™s?", "voc√™s s√£o confi√°veis?", "aceitam cart√£o?"  
‚Äî ent√£o entenda que √© uma d√∫vida gen√©rica.  
Escolha: **"responderDuvidasGenericas"**

5. Se o cliente fizer qualquer pergunta sobre *BOLETO*  ou demonstrar curiosidade qualquer curiosidade sobre como funciona o *BOLETO* ou credi√°rio, sem confirmar fechamento (ex: ‚Äúcomo funciona o boleto?‚Äù, ‚Äúqual valor de entrada?‚Äù, ‚Äúcomo fa√ßo?‚Äù), ent√£o:Escolha: **"perguntarSobreBoleto"**

 

      Retorne apenas isso:
      {
        "acao": "NOME_DA_ACAO",
        "motivo": "Texto explicando por que esta a√ß√£o foi escolhida",
        "argumento": {
          "nomeModelo": ""
        }
      }
      `;

      const resp = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [{ role: "user", content: prompt }],
        temperature: 0.9
      });

      const raw = resp.choices?.[0]?.message?.content || "";
      const jsonMatch = raw.match(/\{[\s\S]*\}/);
      if (!jsonMatch) return null;
      return JSON.parse(jsonMatch[0]);
    };


    let resultadoTOA = await deliberarPossibilidades();
    let acaoEscolhida = resultadoTOA?.acao;
    console.log("üéØ Resultado TOA:", JSON.stringify(resultadoTOA, null, 2));

   // üõ†Ô∏è Fallback se TOA escolher responderDuvida
if (acaoEscolhida === "responderDuvida") {
  const normalizar = (str) => str.toLowerCase().normalize("NFD").replace(/[\u0300-\u036f]/g, "").trim();

  // üîç Tenta identificar o nome do modelo citado
  let nomeIdentificado = resultadoTOA.argumento?.nomeModelo?.trim();

  // 1Ô∏è‚É£ Se ainda n√£o tem nomeModelo, tenta extrair da entrada
  if (!nomeIdentificado) {
    const citado = modelos.find(m => entrada.toLowerCase().includes(normalizar(m.nome)));
    if (citado) nomeIdentificado = citado.nome;
    else if (quotedMessage) {
      const mencionado = modelos.find(m => quotedMessage.toLowerCase().includes(normalizar(m.nome)));
      if (mencionado) nomeIdentificado = mencionado.nome;
    }
  }

  // 2Ô∏è‚É£ Se ainda n√£o tem, busca no banco por similaridade textual
  if (!nomeIdentificado) {
    const todos = await getAllCelulares();
    const matchBanco = todos.find(m => entrada.toLowerCase().includes(normalizar(m.nome)));
    if (matchBanco) nomeIdentificado = matchBanco.nome;
  }

  if (nomeIdentificado) {
    resultadoTOA.argumento = resultadoTOA.argumento || {};
    resultadoTOA.argumento.nomeModelo = nomeIdentificado;

    // ‚ö†Ô∏è Verifica se esse modelo j√° foi demonstrado
    const historico = await getConversation(sender);
    const foiDemonstrado = historico.some(m => {
      try {
        const obj = typeof m === "string" ? JSON.parse(m) : m;
        const nomeModeloHist = typeof obj.conteudo === "string" ? obj.conteudo : obj.conteudo?.nome;
        return (
          (obj?.tipo === "modelo_confirmado" || obj?.tipo === "modelo_sugerido_json") &&
          normalizar(nomeModeloHist || "") === normalizar(nomeIdentificado)
        );
      } catch {
        return false;
      }
    });
    

    if (!foiDemonstrado) {
      // ‚ö†Ô∏è O modelo existe no banco mas n√£o foi demonstrado ‚Üí precisa mudar a a√ß√£o!
      console.log(`üõ†Ô∏è Corrigindo TOA: modelo "${nomeIdentificado}" citado mas ainda n√£o demonstrado. Mudando para demonstracaoPorNome`);
      resultadoTOA.acao = "agenteDeDemonstracaoPorNomePorValor";
      acaoEscolhida = "agenteDeDemonstracaoPorNomePorValor"; // importante sobrescrever para que o handler correto execute
    }
  }
}   

    // üîê Grava modelo confirmado s√≥ se a TOA deliberar isso com clareza
    if (acaoEscolhida === "agenteDeDemonstracaoPorNomePorValor") {
      const nomeModelo = resultadoTOA.argumento?.nomeModelo?.trim();
      if (nomeModelo && !modelosConfirmados.includes(nomeModelo)) {
        await appendToConversation(sender, {
          tipo: "modelo_confirmado",
          conteudo: nomeModelo,
          timestamp: new Date().toISOString()
        });
      }
    }

    // ‚úÖ ‚¨áÔ∏è Aqui tratamos ambiguidade se a TOA escolher mostrarResumoModelo
    if (acaoEscolhida === "demonstracaoDetalhada") {
      let nomeModelo = resultadoTOA.argumento?.nomeModelo?.trim();    

      if (!nomeModelo) {
        if (modelosConfirmados.length === 1) {
          // S√≥ um modelo confirmado ‚Üí usar direto
          nomeModelo = modelosConfirmados[0];
          resultadoTOA.argumento.nomeModelo = nomeModelo;

          await appendToConversation(sender, {
            tipo: "modelo_confirmado",
            conteudo: nomeModelo,
            timestamp: new Date().toISOString()
          });

        } else {
          // M√∫ltiplos modelos ou nenhum ‚Üí pedir confirma√ß√£o  
          await setUserStage(sender, "agente_de_demonstracao_detalhada");

          await sendBotMessage(sender, `‚ö†Ô∏è ${nomeUsuario}, voc√™ falou que quer fechar, mas fiquei na d√∫vida sobre qual modelo exatamente.`);

          if (modelosConfirmados.length > 1) {
            const lista = modelosConfirmados.map(m => `‚úîÔ∏è *${m}*`).join("\n");
            await sendBotMessage(sender, `Voc√™ pode confirmar qual desses modelos quer?\n\n${lista}`);
          } else {
            await sendBotMessage(sender, `Voc√™ pode me dizer qual o modelo que quer fechar?`);
          }

          return; // ‚ö†Ô∏è IMPORTANTE: n√£o segue pro handler se ainda n√£o temos nomeModelo
        }
      }
      // ‚úÖ Garante que o modelo est√° gravado como confirmado
      if (!modelosConfirmados.includes(nomeModelo)) {
        await appendToConversation(sender, {
          tipo: "modelo_confirmado",
          conteudo: nomeModelo,
          timestamp: new Date().toISOString()
        });
      }

    }

    // üé¨ Execu√ß√£o da a√ß√£o
    if (handlers[acaoEscolhida]) {
      return await handlers[acaoEscolhida](sender, resultadoTOA.argumento || {}, {
        msgContent: entrada,
        quotedMessage,
        pushName,
        conversaCompleta
      });

    }

    return await sendBotMessage(sender, "‚ö†Ô∏è N√£o entendi sua escolha. Pode repetir?");
  } catch (error) {
    console.error("‚ùå Erro no agente TOA:", error);
    return await sendBotMessage(sender, "‚ö†Ô∏è Ocorreu um erro. Pode tentar de novo?");
  }
};

const handlers = {
  demonstracaoDetalhada: async (sender, args, extras) => {
    await setUserStage(sender, "agente_de_demonstracao_detalhada");

    const historico = await getConversation(sender);

    const modeloJaMostrado = historico.some((m) =>
      m?.tipo === "modelo_sugerido_json" &&
      typeof m?.conteudo?.nome === "string" &&
      m.conteudo.nome.toLowerCase() === args.nomeModelo.toLowerCase()
    );

    // üìÇ Carrega o modelo se ele ainda n√£o foi mostrado
    let modeloEscolhido = null;
    if (!modeloJaMostrado && args?.modeloMencionado) {
      const modelos = await getAllCelulares();
      modeloEscolhido = modelos.find(m =>
        m.nome.toLowerCase() === args.modeloMencionado.toLowerCase()
      );
    }

    // üîñ Fallback: tenta encontrar o modelo por nomeModelo se ainda n√£o foi definido
    if (!modeloEscolhido && args?.nomeModelo) {
      const modelos = await getAllCelulares();
      modeloEscolhido = modelos.find(m =>
        m.nome.toLowerCase() === args.nomeModelo.toLowerCase()
      );
    }

    // üìÇ Se n√£o achou o modelo, avisa
    if (!modeloEscolhido) {
      return await sendBotMessage(sender, `‚ö†Ô∏è Ops, n√£o consegui encontrar esse modelo agora. Pode repetir o nome certinho pra mim?`);
    }

    // üìÖ Salva como modelo confirmado (para refer√™ncia futura)
    await appendToConversation(sender, {
      tipo: "modelo_confirmado",
      conteudo: modeloEscolhido.nome,
      timestamp: new Date().toISOString()
    });

    return await handlersDemonstracaoDetalhada.mostrarResumoModelo(sender,
      { nomeModelo: modeloEscolhido.nome },
      { modeloEscolhido });
  },
   responderDuvida: async (sender, args, extras) => {
    await setUserStage(sender, "identificar_modelo_por_nome_pos_demonstracao_por_valor");

    const { msgContent, quotedMessage } = extras;

    const entrada = await sanitizarEntradaComQuoted(sender, msgContent, quotedMessage);

    const { modelos, nomeUsuario, modelosConfirmados, conversaCompleta } = await prepararContextoDeModelosRecentesFluxo(sender);

    if (modelos.length === 0) {
      return await sendBotMessage(sender, "‚ö†Ô∏è Ainda n√£o te mostrei nenhum modelo pra comparar. Quer ver algumas op√ß√µes?");
    }

    let modeloFocado = null;

    if (args?.nomeModelo) {
      const normalizar = (str) => str.toLowerCase().normalize("NFD").replace(/[\u0300-\u036f]/g, "").trim();
      const nomeNormalizado = normalizar(args.nomeModelo);

      // 1Ô∏è‚É£ Tenta encontrar entre os modelos recentes
      modeloFocado = modelos.find(m => normalizar(m.nome) === nomeNormalizado);

      // 2Ô∏è‚É£ Fallback: busca no banco se n√£o estiver entre os recentes
      if (!modeloFocado) {
        const todos = await getAllCelulares();
        modeloFocado = todos.find(m => normalizar(m.nome) === nomeNormalizado);
      }
    }


    let descricaoModelos = "";

    if (modeloFocado) {
      descricaoModelos = `
  ‚û°Ô∏è *${modeloFocado.nome}*
  üí¨ Descri√ß√£o: ${modeloFocado.descricaoCurta}
  üß† Subt√≠tulo: ${modeloFocado.subTitulo}
  üí° Frase impacto: ${modeloFocado.fraseImpacto}
  üíµ Pre√ßo: R$ ${modeloFocado.preco.toFixed(2)}
  üí≥ Parcelado: ${modeloFocado.precoParcelado}
  üñºÔ∏è Imagem: ${modeloFocado.imagemURL}
  `;
    } else {
      descricaoModelos = modelos.map(m => `
  ‚û°Ô∏è *${m.nome}*
  üí¨ Descri√ß√£o: ${m.descricaoCurta}
  üß† Subt√≠tulo: ${m.subTitulo}
  üí° Frase impacto: ${m.fraseImpacto}
  üíµ Pre√ßo: R$ ${m.preco.toFixed(2)}
  üí≥ Parcelado: ${m.precoParcelado}
  üñºÔ∏è Imagem: ${m.imagemURL}
  `).join("\n");
    }
    // üîÅ Se o modelo focado veio do banco e ainda n√£o est√° na lista, adiciona na lista de modelos
    if (modeloFocado && !modelos.find(m => m.nome.toLowerCase() === modeloFocado.nome.toLowerCase())) {
      modelos.push(modeloFocado);
    }

    const historico = await getConversation(sender);
    const ultimaTOA = [...historico].reverse().find(msg => msg.tipo === "deliberacao_toa");

    const contexto = `
    Voc√™ √© Anna, especialista da Vertex Store.
    
    Siga exatamente as diretrizes abaixo para responder qualquer cliente:
    
    TOM DE VOZ:
    ${JSON.stringify(tomDeVozVertex, null, 2)}
    
    OBJE√á√ïES COMUNS:
    ${JSON.stringify(obje√ß√µesVertex, null, 2).slice(0, 3000)}
     
    
    GATILHOS EMOCIONAIS:
    ${JSON.stringify(gatilhosEmocionaisVertex, null, 2)}
    `;

    // üß† Prompt formatado para a IA
    const prompt = `
   ## OBJETIVO
  Guiar o cliente at√© escolher um smartphone da lista apresentada e fechar a venda,
  sempre valorizando experi√™ncia, suporte humanizado e diferencial da loja.
  esteja sempre preparado para responder duvidas de obje√ß√µes que n√£o necessariamente ligados ao modelo em si, utlize a documenta√ß√£o para respoder essa obje√ß√µes e seja criativo
  
  ## TOM_DE_VOZ
  - Sauda√ß√£o acolhedora por√©m direta.
  - Use vocativo informal respeitoso (ex.: ‚ÄúPerfeito, ${nomeUsuario}!‚Äù).
  - Emojis: üíú obrigat√≥rio + 1 contextual; use üî• para descontos.
  - At√© 250 caracteres por bloco; quebre linhas por assunto.
  - Pontua√ß√£o dupla (‚Äú!!‚Äù, ‚Äú‚Ä¶‚Äù ) permitida.

  ## GATILHOS_EMOCIONAIS
  - Priorize Seguran√ßa ‚ûú Rapidez ‚ûú Transfer√™ncia de dados na hora.
  - Explore ‚ÄúGarantia emp√°tica‚Äù, ‚ÄúTelefone reserva‚Äù, ‚ÄúLoja f√≠sica confi√°vel‚Äù.
  - Conecte benef√≠cios √† vida di√°ria (produtividade, mem√≥rias, status).

  ## OBJE√á√ïES & COMPARATIVOS
  - Se cliente comparar pre√ßo online ‚Üí explique valor agregado (lista de diferenciais).
  - Descontos: 100 reais no pagamento a vista no pix. So fale sobre isso em ultimo caso e se o cliente pedir desconto.
  - Parcelamento padr√£o apenas em 10√ó se o cliente insistir parcelamos no maximo em 12x; .
  - Use analogias para comparar servi√ßos (ex.: ‚Äúcomprar s√≥ pre√ßo √© como‚Ä¶‚Äù).
  - Em compara√ß√µes com pre√ßo online fale sobre muitos marketplace venderem modelos indianos de baixa qualidade

 ## REGRAS_DE_INDECIS√ÉO
- Em caso de d√∫vida ou indecis√£o, atue como consultor confi√°vel, trazendo clareza e seguran√ßa.
- Reforce os diferenciais da Vertex:
  Pronta entrega üí® | P√≥s-venda humanizado üíú | Garantia local | Teste/backup na hora üîßüì≤
- Use perguntas abertas para desbloquear a decis√£o:
  - ‚ÄúQual parte voc√™ quer que eu explique melhor?‚Äù
  - ‚ÄúEst√° comparando com outro modelo ou loja?‚Äù
- Ofere√ßa ajuda direta:
  - ‚ÄúQuer que eu compare dois modelos pra facilitar?‚Äù
  - ‚ÄúPrefere decidir por c√¢mera, bateria ou desempenho?‚Äù
- Finalize com call-to-action leve:
  - ‚ÄúQuer que eu mostre o resumo e voc√™ decide com calma?‚Äù
- Quando a indecis√£o n√£o for tecnica de aparelho nem sobre valores
  - "responda com criatividade em cima da obje√ß√£o"

  ## REGRAS_DE_ESTILO
  - Nunca comece com sauda√ß√£o completa; a conversa j√° est√° em andamento.
  - Seja conciso e humanizado; m√°ximo 3 blocos (‚Äúemo√ß√£o‚Äù, ‚Äúbenef√≠cio‚Äù, ‚Äúcall-to-action‚Äù).
  - Sempre feche perguntando algo que avance (ex.: ‚ÄúFecho em 10√ó pra voc√™?‚Äù, "Vamos fechar sua compra?").

   "localizacaoLoja": 
      "endereco": "Av. Get√∫lio Varga, 333, Centro, Araruama - RJ, Brasil. CEP 28979-129",
      "referencia": "Mesma cal√ßada da loteria e xerox do bol√£o, em frente √† faixa de pedestre",
      "horarioFuncionamento": "De 09:00 √†s 19:00, de segunda a s√°bado"
  
  üß† √öltima mensagem do cliente:
      "${entrada}"

  üìú Hist√≥rico da conversa:
        ${conversaCompleta}
 Utilize a ultima decis√£o TOA para te ajudar na resolu√ß√£o de duvida
        ${ultimaTOA}           
      
      üì± Modelos apresentados:
      ${modelos.map(m => `‚û°Ô∏è *${m.nome}*\nüìù ${m.descricaoCurta}\nüíµ Pre√ßo: R$ ${m.preco.toFixed(2)}`).join("\n")}
      
      Nome do cliente: ${nomeUsuario}
      
      ‚úÖ Modelos confirmados anteriormente pelo cliente:
      ${modelosConfirmados.length > 0
        ? modelosConfirmados.map(m => `‚úîÔ∏è *${m}*`).join("\n")
        : "Nenhum ainda foi confirmado."}
      
      üß† √öltimo modelo confirmado:
      ${modelosConfirmados[modelosConfirmados.length - 1] || "nenhum"}
  `;

    const respostaIA = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: contexto },
        { role: "user", content: prompt }
      ],
      temperature: 1.0,
      max_tokens: 200
    });

    const respostaFinal = respostaIA.choices[0]?.message?.content?.trim();

    if (!respostaFinal) {
      return await sendBotMessage(sender, "üìå Estou verificando... Pode repetir a d√∫vida de forma diferente?");
    }

    return await sendBotMessage(sender, respostaFinal);
  },
  responderDuvidasGenericas: async (sender, args, extras) => {
    await setUserStage(sender, "identificar_modelo_por_nome_pos_demonstracao_por_valor");
      const { msgContent, quotedMessage, pushName } = extras;
      const nomeUsuario = pushName || "cliente";
    
      // üßº Entrada enriquecida com texto do quoted
      const entrada = await sanitizarEntradaComQuoted(sender, msgContent, quotedMessage);
    
      // ‚è∫Ô∏è Salva como d√∫vida geral
      await appendToConversation(sender, {
        tipo: "duvida_geral",
        conteudo: entrada,
        timestamp: new Date().toISOString()
      });
    
      // üìö Carrega o contexto completo da conversa
      const {
        modelos,
        nomeUsuario: nomeUsuarioContextual,
        conversaCompleta,
        modelosConfirmados
      } = await prepararContextoDeModelosRecentesFluxo(sender);
    
      const prompt = `
    Voc√™ √© Anna, especialista da Vertex Store üíú
    
    Responda a seguinte d√∫vida do cliente com empatia, clareza e foco em ajudar de forma informal e acolhedora.
    
    üîç Entrada do cliente:
    "${entrada}"
    
    üì¶ Modelos sugeridos:
    ${modelos.length > 0
        ? modelos.map(m => `‚û°Ô∏è ${m.nome} - ${m.descricaoCurta} - R$ ${m.preco.toFixed(2)}`).join("\n")
        : "Nenhum modelo sugerido ainda."}
    
    ‚úîÔ∏è Modelos confirmados:
    ${modelosConfirmados.length > 0
        ? modelosConfirmados.map(m => `‚úîÔ∏è ${m}`).join("\n")
        : "Nenhum confirmado ainda."}
    
    üìú Hist√≥rico recente:
    ${conversaCompleta}
    
    üí° Instru√ß√µes:
    - Se a d√∫vida for sobre produto, pre√ßo, garantia ou suporte ‚Üí responda com clareza.
    - Se for uma d√∫vida fora do escopo (ex: troca, defeito, localiza√ß√£o), oriente e diga que ser√° encaminhada.
    - Use tom humano, emp√°tico, com emoji üíú e uma pergunta no final.
  
    "localizacaoLoja":  
        "endereco": "Av. Get√∫lio Varga, 333, Centro, Araruama - RJ, Brasil. CEP 28979-129",
        "referencia": "Mesma cal√ßada da loteria e xerox do bol√£o, em frente √† faixa de pedestre",
        "horarioFuncionamento": "De 09:00 √†s 19:00, de segunda a s√°bado"
    `;
    
      const respostaIA = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [
          { role: "system", content: `Voc√™ √© uma atendente da Vertex Store, informal, clara e acolhedora.` },
          { role: "user", content: prompt }
        ],
        temperature: 0.9,
        max_tokens: 350
      });
    
      const respostaFinal = respostaIA.choices?.[0]?.message?.content?.trim();
    
      if (!respostaFinal) {
        return await sendBotMessage(sender, "üì© Recebi sua d√∫vida, e j√° estou vendo com a equipe! J√° te retorno üíú");
      }
    
      return await sendBotMessage(sender, respostaFinal);
  },
  agenteDeDemonstracaoPorNomePorValor: async (sender, args, { msgContent, pushName }) => {
    await setUserStage(sender, "agente_de_demonstracao_por_nome_por_valor");
    // Salva como modelo confirmado
    const nomeModelo = args?.nomeModelo?.trim();

    return await agenteDeDemonstracaoPorNomePorValor({ sender, msgContent, pushName, modeloMencionado: nomeModelo });
    
  },
  perguntarSobreBoleto: async (sender, args, { pushName, msgContent }) => {  
    await setUserStage(sender, "perguntar_sobre_boleto");
  
     
    const delay = (ms) => new Promise((resolve) => setTimeout(resolve, ms));
    await delay(2000);

    const nomeUsuario = await getNomeUsuario(sender)
  
    await sendBotMessage(sender, `${nomeUsuario} para vendas no boleto temos modelos e condi√ß√µes diferentes. Me ajuda a entender algumas coisas antes`);
   
    return await rotinaDeBoleto({ sender, msgContent, pushName });
  }
  
}



module.exports = { identificarModeloPorNomePosDemonstra√ß√£oPorValor,
  handlers
 };
