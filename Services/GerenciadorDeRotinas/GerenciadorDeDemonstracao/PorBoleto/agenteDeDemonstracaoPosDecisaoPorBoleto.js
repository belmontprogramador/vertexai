const { sendBotMessage } = require("../../../messageSender");
const {
  setUserStage,  
  appendToConversation
} = require("../../../redisService");
const { informacoesPayjoy } = require("../../../utils/documentacoes/informacoesPayjoy");
const { gatilhosEmocionaisVertex } = require('../../../utils/documentacoes/gatilhosEmocionais');
const { tomDeVozVertex } = require('../../../utils/documentacoes/tomDeVozVertex');
const { objeÃ§ÃµesVertexBoleto } = require("../../../utils/documentacoes/objecoesBoleto");;
const { handlers: handlersDemonstracaoDetalhadaBoleto, agenteDeDemonstracaoDetalhadaBoleto } = require("../../../GerenciadorDeRotinas/GerenciadorDeDemonstracao/agenteDeDemonstracaoDetalhadaBoleto");
const { getConversation } = require("../../../HistoricoDeConversas/conversationManager");
const { getAllCelulareBoleto } = require('../../../dbService')
const { sanitizarEntradaComQuoted } = require("../../../utils/utilitariosDeMensagem/sanitizarEntradaComQuoted");
const { prepararContextoDeModelosRecentes } = require("../../../utils/utilitariosDeMensagem/prepararContextoDeModelosRecentes");
const OpenAI = require("openai");
const { agenteDeDemonstracaoPorNomePorBoleto } = require("./agenteDeDemonstracaoPorNomePorBoleto");
const { enviarResumoParaNumeros } = require("../../../utils/enviarResumoParaNumeros");
const { registrarTagModeloConfirmado } = require("../../../ServicesKommo/registrarTagModeloConfirmado");
require("dotenv").config();
const { atualizarValorVendaDoLead } = require("../../../ServicesKommo/atualizarValorVendaDoLead");
const { pipelineAtendimentoHumanoBoleto } = require("../../../ServicesKommo/pipelineAtendimentoHumanoBoleto");



const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const obterModelosDoBling = async () => {
  try {
    const celulares = await getAllCelulareBoleto();

    const termosIgnorados = [
      "BLACK", "WHITE", "BLUE", "GREEN", "GOLD", "PURPLE", "SILVER", "CORAL",
      "MIDNIGHT", "OCEAN", "TEAL", "AZUL", "VERDE", "LAVENDER", "VOYAGE",
      "MARBLE", "STORM", "LIGHTNING", "SPARKLE", "DARK", "LIME", "STAR", "STARRY",
      "OCÃ‰ANO", "ROM", "RAM"
    ];

    const normalizeNome = (nome) => nome
      .replace(/^smartphone\s*/i, "")
      .replace(/[^\w\s]/gi, '')
      .trim()
      .split(/\s+/)
      .filter(p => !termosIgnorados.includes(p.toUpperCase()))
      .join(" ")
      .toLowerCase()
      .trim();

    const mapaUnico = new Map();

    for (const c of celulares) {
      const chave = normalizeNome(c.nome);
      if (!mapaUnico.has(chave)) {
        mapaUnico.set(chave, {
          nome: c.nome,
          preco: c.preco,
          descricaoCurta: c.descricao,
          imagemURL: c.imageURL,
          precoParcelado: c.precoParcelado,
          fraseImpacto: c.fraseImpacto,
          subTitulo: c.subTitulo
        });
      }
    }

    const listaParaPrompt = Array.from(mapaUnico.values());

    console.log("ðŸ“¦ Modelos carregados do banco:");
    listaParaPrompt.forEach(m => console.log("-", m.nome));

    return listaParaPrompt;
  } catch (err) {
    console.error("âŒ Erro ao carregar modelos do banco:", err);
    return [];
  }
};

const calcularSimilaridadePorEmbeddings = async (entrada, modelos) => {
  const entradaEmbedding = await openai.embeddings.create({
    model: "text-embedding-3-small",
    input: entrada
  });

  const nomesModelos = modelos.map(m => m.nome);

  const modelosEmbedding = await openai.embeddings.create({
    model: "text-embedding-3-small",
    input: nomesModelos
  });

  const vetorEntrada = entradaEmbedding.data[0].embedding;

  const distancias = modelosEmbedding.data.map((item, i) => {
    const modeloOriginal = modelos[i];
    const vetorModelo = item.embedding;
    const score = vetorEntrada.reduce((acc, val, idx) => acc + val * vetorModelo[idx], 0);
    return {
      imagemURL: modeloOriginal.imagemURL,
      descricaoCurta: modeloOriginal.descricaoCurta,
      modelo: modeloOriginal.nome,
      preco: modeloOriginal.preco,
      subTitulo: modeloOriginal.subTitulo,
      fraseImpacto: modeloOriginal.fraseImpacto,
      precoParcelado: modeloOriginal.precoParcelado,
      score
    };
  });

  return distancias.sort((a, b) => b.score - a.score);
};

const agenteDeDemonstracaoPosDecisaoPorBoleto = async ({ sender, msgContent, pushName, quotedMessage }) => {
  try {
    await setUserStage(sender, "agente_de_demonstracao_pos_decisao_por_boleto");

    const entrada = await sanitizarEntradaComQuoted(sender, msgContent, quotedMessage);

    const { modelos, modelosConfirmados, nomeUsuario, conversaCompleta } = await prepararContextoDeModelosRecentes(sender);

    // ðŸŽ¯ Tenta detectar similaridade de entrada com algum modelo
    const listaModelos = await obterModelosDoBling();
    const similares = await calcularSimilaridadePorEmbeddings(entrada, listaModelos);
    const maisProvavel = similares?.[0];

    if (maisProvavel?.score > 0.90) {
      console.log("âœ… Entrada casa fortemente com modelo:", maisProvavel.modelo);
      await appendToConversation(sender, {
        tipo: "deliberacao_toa",
        conteudo: {
          acao: "demonstracaoDetalhadaBoleto",
          motivo: `Cliente mencionou ${maisProvavel.modelo} com alta similaridade`,
          argumento: { modeloMencionado: maisProvavel.modelo }
        },
        timestamp: new Date().toISOString()
      });

      return await handlers.demonstracaoDetalhadaBoleto(sender, {
        modeloMencionado: maisProvavel.modelo
      }, { msgContent: entrada });
    }

    // ðŸ¤– DeliberaÃ§Ã£o TOA
    const deliberarPossibilidades = async () => {
      const prompt = `
      ðŸ“œ HistÃ³rico da conversa:
        ${conversaCompleta}
      
      ðŸ§  Ãšltima mensagem do cliente:
      "${entrada}"
      
      ðŸ“± Modelos apresentados:
      ${modelos.map(m => `âž¡ï¸ *${m.nome}*\nðŸ“ ${m.descricaoCurta}\nðŸ’µ PreÃ§o: R$ ${m.preco.toFixed(2)}`).join("\n")}
      
      Nome do cliente: ${nomeUsuario}
      
      âœ… Modelos confirmados anteriormente pelo cliente:
      ${modelosConfirmados.length > 0
        ? modelosConfirmados.map(m => `âœ”ï¸ *${m}*`).join("\n")
        : "Nenhum ainda foi confirmado."}
      
      ðŸ§  Ãšltimo modelo confirmado:
      ${modelosConfirmados[modelosConfirmados.length - 1] || "nenhum"}
      
      ðŸ’¡ Quais sÃ£o as 3 possibilidades mais provÃ¡veis que o cliente quer com essa mensagem?
      
      1. **demonstracaoDetalhadaBoleto** â†’ quando estiver decidido ou indicar desejo de finalizar, mesmo que sem palavras exatas como "fechou". Ex: â€œgostei muito desseâ€, â€œacho que vou aÃ­ amanhÃ£â€, â€œvamos ver esse aÃ­â€.
      1.1 - Se o cliente disser explicitamente que quer quer fechar a venda respondendo a pergunta do bot sobre visitar a loja. Escolha **demonstracaoDetalhadaBoleto**.
      2. Se o cliente fizer QUALQUER pergunta (mesmo sem ponto de interrogaÃ§Ã£o) â€” como "Ã© bom?", "e esse?", "a cÃ¢mera Ã© boa?", "qual o preÃ§o?" â€” **sobre qualquer um dos modelos apresentados anteriormente**, ou **sobre o Ãºltimo modelo confirmado**, interprete como dÃºvida ou indecisÃ£o. Escolha **responderDuvida**.
      
      âš ï¸ Mesmo se o cliente mencionar o nome do modelo de novo ou comparÃ¡-lo com outro lugar (ex: Mercado Livre), se esse modelo jÃ¡ foi apresentado, ainda assim escolha **responderDuvida**, pois o cliente jÃ¡ demonstrou interesse anteriormente.
      
      3. Se ele mencionar um modelo que **ainda nÃ£o foi apresentado na conversa** e **tambÃ©m nÃ£o Ã© o Ãºltimo confirmado**, escolha **agenteDeDemonstracaoPorNomePorBoleto**. Isso indica que o cliente estÃ¡ abrindo uma nova intenÃ§Ã£o.
      
       4. Se a mensagem do cliente **nÃ£o mencionar nenhum modelo**,  
e a dÃºvida parecer geral, filosÃ³fica, comportamental ou fora do escopo dos modelos â€”  
ex: "vocÃªs vendem usados?", "e se der defeito?", "vocÃªs tem loja fÃ­sica?",  
"qual Ã© o diferencial de vocÃªs?", "vocÃªs sÃ£o confiÃ¡veis?", "aceitam cartÃ£o?"  
â€” entÃ£o entenda que Ã© uma dÃºvida genÃ©rica.  
Escolha: **"responderDuvidasGenericas"**

      Retorne apenas isso:
      {
        "acao": "NOME_DA_ACAO",
        "motivo": "Texto explicando por que esta aÃ§Ã£o foi escolhida",
        "argumento": {
          "nomeModelo": ""
        }
      }
      `;     

      const resp = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [{ role: "user", content: prompt }],
        temperature: 0.9
      });

      const raw = resp.choices?.[0]?.message?.content || "";
      const jsonMatch = raw.match(/\{[\s\S]*\}/);
      if (!jsonMatch) return null;
      return JSON.parse(jsonMatch[0]);
    };

    const resultadoTOA = await deliberarPossibilidades();
    const acaoEscolhida = resultadoTOA?.acao;
    console.log("ðŸŽ¯ Resultado TOA:", JSON.stringify(resultadoTOA, null, 2));

    // ðŸ” Grava modelo confirmado sÃ³ se a TOA deliberar isso com clareza
if (acaoEscolhida === "agenteDeDemonstracaoPorNomePorBoleto") {
  const nomeModelo = resultadoTOA.argumento?.nomeModelo?.trim();
  if (nomeModelo && !modelosConfirmados.includes(nomeModelo)) {
    await appendToConversation(sender, {
      tipo: "modelo_confirmado",
      conteudo: nomeModelo,
      timestamp: new Date().toISOString()
    });
  }
}

  // âœ… â¬‡ï¸ Aqui tratamos ambiguidade se a TOA escolher mostrarResumoModeloBoleto
if (acaoEscolhida === "demonstracaoDetalhadaBoleto") {
  let nomeModelo = resultadoTOA.argumento?.nomeModelo?.trim();
  console.log(`aqui dentro do pos decisÃ£o eu chamei o resumomodelo com esse modelo confirmado ${nomeModelo}`)

  if (!nomeModelo) {
    if (modelosConfirmados.length === 1) {
      // SÃ³ um modelo confirmado â†’ usar direto
      nomeModelo = modelosConfirmados[0];
      resultadoTOA.argumento.nomeModelo = nomeModelo;

      await appendToConversation(sender, {
        tipo: "modelo_confirmado",
        conteudo: nomeModelo,
        timestamp: new Date().toISOString()
      });

    } else {
      // MÃºltiplos modelos ou nenhum â†’ pedir confirmaÃ§Ã£o  
      await setUserStage(sender, "agente_de_demonstracao_detalhada_boleto");   

      await sendBotMessage(sender, `âš ï¸ ${nomeUsuario}, vocÃª falou que quer fechar, mas fiquei na dÃºvida sobre qual modelo exatamente.`);

      if (modelosConfirmados.length > 1) {
        const lista = modelosConfirmados.map(m => `âœ”ï¸ *${m}*`).join("\n");
        await sendBotMessage(sender, `VocÃª pode confirmar qual desses modelos quer?\n\n${lista}`);
      } else {
        await sendBotMessage(sender, `VocÃª pode me dizer qual o modelo que quer fechar?`);
      }

      return; // âš ï¸ IMPORTANTE: nÃ£o segue pro handler se ainda nÃ£o temos nomeModelo
    }
  }
  
 // âœ… Garante que o modelo estÃ¡ gravado como confirmado
 if (!modelosConfirmados.includes(nomeModelo)) {
  await appendToConversation(sender, {
    tipo: "modelo_confirmado",
    conteudo: nomeModelo,
    timestamp: new Date().toISOString()
  });
}
  
}

// ðŸŽ¬ ExecuÃ§Ã£o da aÃ§Ã£o
if (handlers[acaoEscolhida]) {
  return await handlers[acaoEscolhida](sender, resultadoTOA.argumento || {}, {
    msgContent: entrada,
    quotedMessage,
    pushName,
    conversaCompleta
  });

  }

    return await sendBotMessage(sender, "âš ï¸ NÃ£o entendi sua escolha. Pode repetir?");
  } catch (error) {
    console.error("âŒ Erro no agente TOA:", error);
    return await sendBotMessage(sender, "âš ï¸ Ocorreu um erro. Pode tentar de novo?");
  }
};

const handlers = {
  demonstracaoDetalhadaBoleto: async (sender, args, extras) => {
    await setUserStage(sender, "agente_de_demonstracao_detalhada_boleto");     
  
    const historico = await getConversation(sender);
  
    const modeloJaMostrado = historico.some((m) =>
      m?.tipo === "modelo_sugerido_json" &&
      typeof m?.conteudo?.nome === "string" &&
      m.conteudo.nome.toLowerCase() === args.nomeModelo.toLowerCase()
    );
  
    let modeloEscolhido;
  
    if (!modeloJaMostrado && args?.modeloMencionado) {
      const modelos = await getAllCelulareBoleto();
      modeloEscolhido = modelos.find(m =>
        m.nome.toLowerCase() === args.modeloMencionado.toLowerCase()
      );
    }
  
     // âœ… Executa o resumo com ou sem modelo prÃ©-exibido
  if (modeloEscolhido) {
    resultado = await handlersDemonstracaoDetalhadaBoleto.mostrarResumoModeloBoleto(
      sender,
      { nomeModelo: modeloEscolhido.nome },
      { modeloEscolhido }
    );
  } else {
    resultado = await handlersDemonstracaoDetalhadaBoleto.mostrarResumoModeloBoleto(
      sender,
      { nomeModelo: args.nomeModelo },
      {}
    );
  }

  // âœ… Sempre envia o resumo apÃ³s mostrar
  await enviarResumoParaNumeros(sender);

  return resultado;
  },  
  responderDuvida: async (sender, args, extras) => {
    await setUserStage(sender, "agente_de_demonstracao_pos_decisao_por_boleto");

    // âœ… Movimenta o lead para o pipeline de atendimento humano, se necessÃ¡rio
  try {
    await pipelineAtendimentoHumanoBoleto(sender);
  } catch (err) {
    console.warn("âš ï¸ Erro ao mover lead para atendimento humano:", err.message);
  }
  
    const { msgContent, quotedMessage } = extras;
    const entrada = await sanitizarEntradaComQuoted(sender, msgContent, quotedMessage);
  
    const { modelos, nomeUsuario, modelosConfirmados, conversaCompleta } =
      await prepararContextoDeModelosRecentes(sender);
  
    if (modelos.length === 0) {
      return await sendBotMessage(sender, "âš ï¸ Ainda nÃ£o te mostrei nenhum modelo pra comparar. Quer ver algumas opÃ§Ãµes?");
    }
  
    let modeloFocado = null;
  
    if (args?.nomeModelo) {
      const normalizar = (str) =>
        str.toLowerCase().normalize("NFD").replace(/[\u0300-\u036f]/g, "").trim();
      const nomeNormalizado = normalizar(args.nomeModelo);
  
      // Tenta encontrar entre os modelos recentes
      modeloFocado = modelos.find((m) => normalizar(m.nome) === nomeNormalizado);
  
      // Fallback: busca no banco se nÃ£o estiver entre os recentes
      if (!modeloFocado) {
        const todos = await getAllCelulareBoleto();
        modeloFocado = todos.find((m) => normalizar(m.nome) === nomeNormalizado);
      }
    }
  
    let descricaoModelos = "";
  
    if (modeloFocado) {
      descricaoModelos = `
  âž¡ï¸ *${modeloFocado.nome}*
  ðŸ’¬ DescriÃ§Ã£o: ${modeloFocado.descricaoCurta}
  ðŸ§  SubtÃ­tulo: ${modeloFocado.subTitulo}
  ðŸ’¡ Frase impacto: ${modeloFocado.fraseImpacto}
  ðŸ’µ PreÃ§o: R$ ${modeloFocado.preco.toFixed(2)}
  ðŸ’³ Parcelado: ${modeloFocado.precoParcelado}
  ðŸ–¼ï¸ Imagem: ${modeloFocado.imagemURL}
  `;
    } else {
      descricaoModelos = modelos.map((m) => `
  âž¡ï¸ *${m.nome}*
  ðŸ’¬ DescriÃ§Ã£o: ${m.descricaoCurta}
  ðŸ§  SubtÃ­tulo: ${m.subTitulo}
  ðŸ’¡ Frase impacto: ${m.fraseImpacto}
  ðŸ’µ PreÃ§o: R$ ${m.preco.toFixed(2)}
  ðŸ’³ Parcelado: ${m.precoParcelado}
  ðŸ–¼ï¸ Imagem: ${m.imagemURL}
  `).join("\n");
    }
  
    // âœ… Sempre registra tag no Kommo se houver modelo focado
    if (modeloFocado) {
      const modeloJaNaLista = modelos.find(m => m.nome.toLowerCase() === modeloFocado.nome.toLowerCase());
      if (!modeloJaNaLista) {
        modelos.push(modeloFocado); // adiciona na lista para IA responder com ele
      }
  
      try {
        await registrarTagModeloConfirmado(sender, modeloFocado.nome);
        console.log(`âœ… Tag registrada para modelo: ${modeloFocado.nome}`);
      } catch (err) {
        console.warn("âš ï¸ Erro ao registrar tag no Kommo:", err.message);
      }

      try {
        await atualizarValorVendaDoLead(`${sender}@c.us`, modeloFocado.preco);
        console.log(`ðŸ’° Valor do lead atualizado para R$ ${modeloFocado.preco}`);
      } catch (err) {
        console.warn("âš ï¸ Erro ao atualizar valor do lead no Kommo:", err.message);
      }
      
    }
  
    const historico = await getConversation(sender);
    const ultimaTOA = [...historico].reverse().find(msg => msg.tipo === "deliberacao_toa");
  
    const contexto = `
  VocÃª Ã© Anna, especialista da Vertex Store.
  
  Siga exatamente as diretrizes abaixo para responder qualquer cliente:
  
  TOM DE VOZ:
  ${JSON.stringify(tomDeVozVertex, null, 2)}
  
  OBJEÃ‡Ã•ES COMUNS:
  ${JSON.stringify(objeÃ§ÃµesVertexBoleto, null, 2).slice(0, 3000)}
  
  OBJEÃ‡Ã•ES SOBRE PAYJOY:
  ${JSON.stringify(informacoesPayjoy).slice(0, 3500)}
  
  GATILHOS EMOCIONAIS:
  ${JSON.stringify(gatilhosEmocionaisVertex, null, 2)}
  `;
  
    const prompt = `
  ## OBJETIVO
  Guiar o cliente atÃ© escolher um smartphone da lista apresentada e fechar a venda,
  sempre valorizando experiÃªncia, suporte humanizado e diferencial da loja.
  Esteja sempre preparado para responder dÃºvidas de objeÃ§Ãµes que nÃ£o necessariamente ligadas ao modelo em si.
  Utilize a documentaÃ§Ã£o para responder essas objeÃ§Ãµes e seja criativo.
  *** SEMPRE ao falar de preÃ§os, deixe claro que sÃ£o estimativas e podem flutuar conforme disponibilidade da PayJoy. ***
  
  ## TOM_DE_VOZ
  - SaudaÃ§Ã£o acolhedora porÃ©m direta.
  - Use vocativo informal respeitoso (ex.: â€œPerfeito, ${nomeUsuario}!â€).
  - Emojis: ðŸ’œ obrigatÃ³rio + 1 contextual; use ðŸ”¥ para descontos.
  - AtÃ© 250 caracteres por bloco; quebre linhas por assunto.
  - PontuaÃ§Ã£o dupla (â€œ!!â€, â€œâ€¦â€ ) permitida.
  
  ## GATILHOS_EMOCIONAIS
  - Priorize SeguranÃ§a âžœ Rapidez âžœ TransferÃªncia de dados na hora.
  - Explore â€œGarantia empÃ¡ticaâ€, â€œTelefone reservaâ€, â€œLoja fÃ­sica confiÃ¡velâ€.
  - Conecte benefÃ­cios Ã  vida diÃ¡ria (produtividade, memÃ³rias, status).
  
  ## OBJEÃ‡Ã•ES & COMPARATIVOS
  - Se cliente comparar preÃ§o online â†’ explique valor agregado (lista de diferenciais).
  - Descontos: no boleto, nÃ£o hÃ¡ descontos.
  - Parcelamento apenas em 18x.
  - Use analogias para comparar serviÃ§os (ex.: â€œcomprar sÃ³ preÃ§o Ã© comoâ€¦â€).
  
  ## REGRAS_DE_ESTILO
  - Nunca comece com saudaÃ§Ã£o completa; a conversa jÃ¡ estÃ¡ em andamento.
  - Seja conciso e humanizado; mÃ¡ximo 3 blocos: â€œemoÃ§Ã£oâ€, â€œbenefÃ­cioâ€, â€œcall-to-actionâ€.
  - Sempre feche perguntando algo que avance (ex.: â€œFecho em 10Ã— pra vocÃª?â€).
  
  ðŸ“ EndereÃ§o:
  Av. GetÃºlio Varga, 333, Centro, Araruama - RJ, Brasil. CEP 28979-129
  ðŸ“Œ ReferÃªncia: Mesma calÃ§ada da loteria e xerox do bolÃ£o, em frente Ã  faixa de pedestre
  ðŸ•˜ Atendimento: De 09:00 Ã s 19:00, de segunda a sÃ¡bado

  **NOS NÃƒO POSSUIMOS IPHONE PARA EVNDA NA LOJA, DIGA DE MODO SUAVE QUE TRABALHAMOS APENAS COM A LINHA REDMI POCO E REALME, HIPOTESE NENHUMA RESPONDE QUE TRABALHOMOS COM IPHONE**
  
  ðŸ§  Ãšltima mensagem do cliente:
  "${entrada}"
  
  ðŸ“œ HistÃ³rico da conversa:
  ${conversaCompleta}
  
  ðŸ§  Ãšltima decisÃ£o TOA:
  ${JSON.stringify(ultimaTOA, null, 2)}
  
  ðŸ“± Modelos apresentados:
  ${descricaoModelos}
  
  âœ”ï¸ Modelos confirmados anteriormente:
  ${modelosConfirmados.length > 0
        ? modelosConfirmados.map(m => `âœ”ï¸ *${m}*`).join("\n")
        : "Nenhum ainda foi confirmado."}
  
  ðŸ§  Ãšltimo modelo confirmado:
  ${modelosConfirmados[modelosConfirmados.length - 1] || "nenhum"}
  `;
  
    const respostaIA = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: contexto },
        { role: "user", content: prompt }
      ],
      temperature: 1.0,
      max_tokens: 200
    });
  
    const respostaFinal = respostaIA.choices?.[0]?.message?.content?.trim();
  
    if (!respostaFinal) {
      return await sendBotMessage(sender, "ðŸ“Œ Estou verificando... Pode repetir a dÃºvida de forma diferente?");
    }
  
    // âœ… Envia resumo para os internos apÃ³s responder dÃºvida sobre modelo
    await enviarResumoParaNumeros(sender);
  
    return await sendBotMessage(sender, respostaFinal);
  }, 
  responderDuvidasGenericas: async (sender, args, extras) => {
    await setUserStage(sender, "agente_de_demonstracao_pos_decisao_por_boleto");
    const { msgContent, quotedMessage, pushName } = extras;
    const nomeUsuario = pushName || "cliente";
  
    // ðŸ§¼ Entrada enriquecida com texto do quoted
    const entrada = await sanitizarEntradaComQuoted(sender, msgContent, quotedMessage);
  
    // âºï¸ Salva como dÃºvida geral
    await appendToConversation(sender, {
      tipo: "duvida_geral",
      conteudo: entrada,
      timestamp: new Date().toISOString()
    });
  
    // ðŸ“š Carrega o contexto completo da conversa
    const {
      modelos,
      nomeUsuario: nomeUsuarioContextual,
      conversaCompleta,
      modelosConfirmados
    } = await prepararContextoDeModelosRecentes(sender);
  
    const prompt = `
  VocÃª Ã© Anna, especialista da Vertex Store ðŸ’œ
  
  Responda a seguinte dÃºvida do cliente com empatia, clareza e foco em ajudar de forma informal e acolhedora.
  
  ðŸ” Entrada do cliente:
  "${entrada}"
  
  ðŸ“¦ Modelos sugeridos:
  ${modelos.length > 0
      ? modelos.map(m => `âž¡ï¸ ${m.nome} - ${m.descricaoCurta} - R$ ${m.preco.toFixed(2)}`).join("\n")
      : "Nenhum modelo sugerido ainda."}
  
  âœ”ï¸ Modelos confirmados:
  ${modelosConfirmados.length > 0
      ? modelosConfirmados.map(m => `âœ”ï¸ ${m}`).join("\n")
      : "Nenhum confirmado ainda."}
  
  ðŸ“œ HistÃ³rico recente:
  ${conversaCompleta}
  
  ðŸ’¡ InstruÃ§Ãµes:
  - Se a dÃºvida for sobre produto, preÃ§o, garantia ou suporte â†’ responda com clareza.
  - Se for uma dÃºvida fora do escopo (ex: troca, defeito, localizaÃ§Ã£o), oriente e diga que serÃ¡ encaminhada.
  - Use tom humano, empÃ¡tico, com emoji ðŸ’œ e uma pergunta no final.

  "localizacaoLoja":  
      "endereco": "Av. GetÃºlio Varga, 333, Centro, Araruama - RJ, Brasil. CEP 28979-129",
      "referencia": "Mesma calÃ§ada da loteria e xerox do bolÃ£o, em frente Ã  faixa de pedestre",
      "horarioFuncionamento": "De 09:00 Ã s 19:00, de segunda a sÃ¡bado"
  `;
  
    const respostaIA = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: `VocÃª Ã© uma atendente da Vertex Store, informal, clara e acolhedora.` },
        { role: "user", content: prompt }
      ],
      temperature: 0.9,
      max_tokens: 350
    });
  
    const respostaFinal = respostaIA.choices?.[0]?.message?.content?.trim();
  
    if (!respostaFinal) {
      return await sendBotMessage(sender, "ðŸ“© Recebi sua dÃºvida, e jÃ¡ estou vendo com a equipe! JÃ¡ te retorno ðŸ’œ");
    }

    // âœ… Envia o resumo para os internos mesmo apÃ³s dÃºvida genÃ©rica
  await enviarResumoParaNumeros(sender);
  
    return await sendBotMessage(sender, respostaFinal);
  },
  agenteDeDemonstracaoPorNomePorBoleto: async (sender, args, { msgContent, pushName }) => {
    await setUserStage(sender, "agente_de_demonstracao_por_nome_por_boleto");
    // Salva como modelo confirmado
    const nomeModelo = args?.nomeModelo?.trim();

    return await agenteDeDemonstracaoPorNomePorBoleto({ sender, msgContent, pushName, modeloMencionado: nomeModelo });
  },
  //mostrar todos os modelos


};



module.exports = {
  agenteDeDemonstracaoPosDecisaoPorBoleto,
  
};

