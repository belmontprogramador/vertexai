// üîÑ Agente GPT completo com l√≥gica igual a identificarModeloPorNome
const { sendBotMessage } = require("../../messageSender");
const {
  setUserStage,
  appendToConversation,
  getConversation,
  getNomeUsuario,
  getUserStage,
} = require("../../redisService");
const { getAllCelulares } = require("../../dbService");
const { rotinaDeAgendamento } = require("../../GerenciadorDeRotinas/GerenciadorDeAgendamento/rotinaDeAgendamento");
const OpenAI = require("openai");
require("dotenv").config();
const { obje√ß√µesVertex } = require("../../utils/documentacoes/objecoes");
const { gatilhosEmocionaisVertex } = require('../../utils/documentacoes/gatilhosEmocionais'); 
const { intencaoDataEntregaDesconto } = require('../../utils/documentacoes/intencaoDataEntregaDesconto');
const { tomDeVozVertex  } = require("../../utils/documentacoes/tomDeVozVertex");
const { extrairTextoDoQuotedMessage } = require("../../utils/utilitariosDeMensagem/extrairTextoDoQuotedMessage");
const { sanitizarEntradaComQuoted } = require("../../utils/utilitariosDeMensagem/sanitizarEntradaComQuoted");
const { prepararContextoDeModelosRecentesFluxo } = require("../../utils/utilitariosDeMensagem/prepararContextoDeModelosRecentesFluxo");

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const obterModelosDoBling = async () => {
  const celulares = await getAllCelulares();

  const termosIgnorados = [
    "BLACK", "WHITE", "BLUE", "GREEN", "GOLD", "PURPLE", "SILVER", "CORAL",
    "MIDNIGHT", "OCEAN", "TEAL", "AZUL", "VERDE", "LAVENDER", "VOYAGE",
    "MARBLE", "STORM", "LIGHTNING", "SPARKLE", "DARK", "LIME", "STAR", "STARRY",
    "OC√âANO", "ROM", "RAM"
  ];

  const normalizeNome = (nome) =>
    nome
      .replace(/^smartphone\s*/i, "")
      .replace(/[^\w\s]/gi, "")
      .trim()
      .split(/\s+/)
      .filter((p) => !termosIgnorados.includes(p.toUpperCase()))
      .join(" ")
      .toLowerCase()
      .trim();

  const mapaUnico = new Map();

  for (const c of celulares) {
    const chave = normalizeNome(c.nome);
    if (!mapaUnico.has(chave)) {
      mapaUnico.set(chave, {
        nome: c.nome,
        preco: c.preco,
        descricaoCurta: c.descricao, // ‚úÖ Corrigido aqui!
        imagemURL: c.imageURL,
        precoParcelado: c.precoParcelado,
        fraseImpacto: c.fraseImpacto,
        subTitulo: c.subTitulo,
        videoURL: c.videoURL,
      });
    }
  }

  return Array.from(mapaUnico.values());
};


const calcularSimilaridadePorEmbeddings = async (entrada, modelos) => {
  const entradaEmbedding = await openai.embeddings.create({ model: "text-embedding-3-small", input: entrada });
  const modelosEmbedding = await openai.embeddings.create({ model: "text-embedding-3-small", input: modelos.map(m => m.nome) });
  const vetorEntrada = entradaEmbedding.data[0].embedding;
  return modelosEmbedding.data.map((item, i) => {
    const m = modelos[i];
    const score = vetorEntrada.reduce((acc, val, idx) => acc + val * item.embedding[idx], 0);
    return { ...m, score };
  }).sort((a, b) => b.score - a.score);
};

 

const  agenteDeDemonstracaoDetalhada = async ({ sender, msgContent, pushName }) => {
  try {
    await setUserStage(sender, "agente_de_demonstracao_detalhada");

    const nome = await getNomeUsuario(sender);
    const textoQuoted = extrairTextoDoQuotedMessage(msgContent);

    let entradaAtual = typeof msgContent === "string" ? msgContent : msgContent?.termosRelacionados || "";     

    await appendToConversation(sender, {
      tipo: "entrada_usuario",
      conteudo: entradaAtual,
      timestamp: new Date().toISOString()
    });

    const conversaArray = await getConversation(sender);
    const conversaCompleta = conversaArray
      .map(msg => {
        try {
          const json = typeof msg === "string" ? JSON.parse(msg) : msg;
          return json.conteudo || "";
        } catch {
          return typeof msg === "string" ? msg : "";
        }
      })
      .filter(Boolean)
      .slice(-10)
      .join(" | ");

    const listaModelos = await obterModelosDoBling();

    const similares = await calcularSimilaridadePorEmbeddings(entradaAtual, listaModelos);
    console.log(`Esse foi o match de similaridade${similares}`)
    const maisProvavel = similares?.[0];
    console.log(`Esse foi o match de similaridade${maisProvavel}`)

    if (maisProvavel?.score > 0.90) {
      console.log("‚úÖ Entrada casa fortemente com modelo:", maisProvavel.modelo);
      await appendToConversation(sender, {
        tipo: "deliberacao_toa",
        conteudo: {
          acao: "mostrarResumoModelo",
          motivo: `Cliente mencionou ${maisProvavel.modelo} com alta similaridade`,
          argumento: { modeloMencionado: maisProvavel.modelo }
        },
        timestamp: new Date().toISOString()
      });

      return await mostrarResumoModelo(sender, {
        modeloMencionado: maisProvavel.modelo
      }, { msgContent: entradaAtual });
    }

    const promptTOA = `
ü§ñ Voc√™ √© Anna, assistente virtual da Vertex Store.

Seu objetivo √© identificar a a√ß√£o ideal com base na inten√ß√£o do cliente.

üìå Entrada:
"${entradaAtual}"

üìú Hist√≥rico da conversa:
${conversaCompleta}

üì¶ Modelos dispon√≠veis:
${listaModelos.map(m => `- ${m.nome}`).join("\n")}

1. **fecharVenda** ‚Üí quando estiver decidido ou indicar desejo de finalizar, mesmo que sem palavras exatas como "fechou". Ex: ‚Äúgostei muito desse‚Äù, ‚Äúacho que vou a√≠ amanh√£‚Äù, ‚Äúvamos ver esse a√≠‚Äù.
‚ö†Ô∏è S√≥ escolha "fecharVenda" se j√° houver uma execu√ß√£o anterior da a√ß√£o "mostrarResumoModelo" com o modelo confirmado. Passe o modelo com argumento

2. Se o cliente fizer **qualquer pergunta**, mesmo curta (ex.: "√© bom?", "qual o pre√ßo?", "tem c√¢mera boa?"), isso significa que ele ainda est√° com d√∫vida e precisa de mais informa√ß√µes. Escolha "responderDuvida".

‚ö†Ô∏è SE o cliente mencionar claramente um modelo (ex: "o note 60 √© bom?"), voc√™ DEVE preencher o campo "argumento.nomeModelo" com o nome exato do modelo mencionado.
‚ö†Ô∏è SE o cliente mencionar qualquer tipo de indecis√£o apos mostrar o resumo do modelo, Escolha "responderDuvida".

3. Se ele mencionar um modelo da lista e n√£o for uma pergunta, escolha "mostrarResumoModelo".

‚ö†Ô∏è Quando escolher "mostrarResumoModelo" voc√™ tamb√©m DEVE preencher "argumento.nomeModelo" com o nome exato do modelo citado.

4. Se o cliente fizer qualquer pergunta sobre *BOLETO*  ou demonstrar curiosidade qualquer curiosidade sobre como funciona o *BOLETO* ou credi√°rio, sem confirmar fechamento (ex: ‚Äúcomo funciona o boleto?‚Äù, ‚Äúqual valor de entrada?‚Äù, ‚Äúcomo fa√ßo?‚Äù), ent√£o:Escolha: **"perguntarSobreBoleto"**


Retorne apenas isso:
{
  "acao": "NOME_DA_ACAO",
  "motivo": "Texto explicando por que esta a√ß√£o foi escolhida",
  "argumento": {}
}`;

    const deliberacao = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [{ role: "user", content: promptTOA }],
      temperature: 0.8
    });

    const jsonMatch = deliberacao.choices?.[0]?.message?.content?.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      console.error("‚ùå TOA n√£o retornou JSON v√°lido.");
      return await sendBotMessage(sender, "‚ö†Ô∏è N√£o consegui entender sua escolha. Pode repetir?");
    }    

    const { acao, motivo, argumento } = JSON.parse(jsonMatch[0]);

    console.log("üß† TOA escolheu:", acao, "‚Üí", motivo);

    await appendToConversation(sender, {
      tipo: "deliberacao_toa",
      conteudo: { acao, motivo, argumento },
      timestamp: new Date().toISOString()
    });

    if (!handlers[acao]) {
      return await sendBotMessage(sender, "‚ö†Ô∏è N√£o entendi sua inten√ß√£o. Pode repetir?");
    }

    return await handlers[acao](sender, argumento, { msgContent: entradaAtual });

  } catch (error) {
    console.error("‚ùå Erro no agenteDeDemonstracaoDetalhada:", error);
    return await sendBotMessage(sender, "‚ö†Ô∏è Ocorreu um erro. Pode tentar de novo?");
  }
};

const handlers = {
  fecharVenda: async (sender, _args, extras) => {
    const { modeloEscolhido, pushName, msgContent } = extras;
    return await rotinaDeAgendamento({ sender, msgContent, pushName });
  },
  mostrarResumoModelo: async (sender, args, extras) => {
    await setUserStage(sender, "agente_de_demonstracao_detalhada");
  
    const nome = await getNomeUsuario(sender);
    let modelo = extras?.modeloEscolhido;
  
    const normalize = (str) =>
      str
        .toLowerCase()
        .normalize("NFD")
        .replace(/[\u0300-\u036f]/g, "")
        .replace(/[^\w\s]/gi, "")
        .replace(/\s+/g, " ")
        .trim();
  
    const listaModelos = await obterModelosDoBling();
  
    // üîé Se n√£o veio modelo direto, tenta pelo nome passado como argumento
    if (!modelo && args?.nomeModelo) {
      modelo = listaModelos.find(m => normalize(m.nome) === normalize(args.nomeModelo));
    }

    await appendToConversation(sender, {
      tipo: "modelo_confirmado",
      conteudo: modelo.nome,
      timestamp: new Date().toISOString()
    });
  
    // üîç Fallback: tenta recuperar do hist√≥rico
    if (!modelo) {
      const historico = await getConversation(sender);
      const confirmados = historico
        .filter(m => m.tipo === "modelo_confirmado")
        .map(m => typeof m.conteudo === "string" ? m.conteudo : "")
        .filter(Boolean);
  
      // ‚ö†Ô∏è Se houver mais de um modelo confirmado, pede escolha expl√≠cita
      if (confirmados.length > 1) {
        return await sendBotMessage(sender, `üìå Perfeito, ${nome}! Conversamos sobre mais de um modelo.\nPode me dizer qual deles voc√™ quer ver agora?`);
      }
  
      // ‚úÖ Se houver apenas um, tenta localizar no cat√°logo
      if (confirmados.length === 1) {
        const confirmado = confirmados[0];
        modelo = listaModelos.find(m => normalize(m.nome) === normalize(confirmado));
      }
    }
  
    if (!modelo) {
      return await sendBotMessage(sender, `‚ö†Ô∏è Opa ${nome}, n√£o consegui identificar com clareza o modelo que voc√™ quer ver.\nPode me dizer o nome exato?`);
    }
  
    // üì¶ Prompt resumido para IA gerar o pitch do modelo
    const prompt = [
      {
        role: "system",
        content: `Voc√™ √© um vendedor persuasivo e direto. 
  Seja direto, com no m√°ximo 3 frases curtas. Priorize clareza e impacto, n√£o ultrapasse 250 caracteres no total.
  
  ***Fa√ßa o mais resumido poss√≠vel para economizar tokens***
  Use uma linguagem formal mas descontra√≠da.
  Pule uma linha entre o resumo e o tom de voz.
  D√™ prefer√™ncia ao pre√ßo parcelado.
  
  Nome do cliente: ${nome}
  
  Ao final, sempre fa√ßa perguntas utilizando esse documento como base:
  TOM DE VOZ:
  ${JSON.stringify(tomDeVozVertex, null, 2)}`
      },
      {
        role: "user",
        content: `Modelo: ${modelo.nome}
        Frase de impacto: ${modelo.fraseImpacto}
        Descri√ß√£o curta: ${modelo.descricaoCurta}
        Pre√ßo √† vista: R$ ${modelo.preco.toFixed(2)}
        Pre√ßo parcelado: ${modelo.precoParcelado || "consulte condi√ß√µes"}`
              }
    ];
  
    let resumo = "";
    try {
      const resposta = await openai.chat.completions.create({
        model: "gpt-4",
        messages: prompt,
        temperature: 0.99,
        max_tokens: 150
      });
  
      resumo = resposta.choices?.[0]?.message?.content?.trim() || "";
    } catch (err) {
      console.error("‚ùå Erro ao gerar resumo com GPT:", err);
      resumo = `üì± *${modelo.nome}*\n${modelo.fraseImpacto}\nüí∞ R$ ${modelo.preco.toFixed(2)}\n\nEm breve te explico mais!`;
    }
  
    // üíæ Salva modelo no hist√≥rico
    await appendToConversation(sender, {
      tipo: "modelo_sugerido_json",
      conteudo: modelo,
      timestamp: new Date().toISOString()
    });

    // üíæ Salva tamb√©m como modelo confirmado (para refer√™ncia futura)
await appendToConversation(sender, {
  tipo: "modelo_confirmado",
  conteudo: modelo.nome,
  timestamp: new Date().toISOString()
});

  
    // üìπ Envia o v√≠deo com resumo na legenda
    if (modelo.videoURL) {
      return await sendBotMessage(sender, {
        videoUrl: modelo.videoURL,
        caption: resumo
      });
    }
  
    // üìÑ Se n√£o tiver v√≠deo, envia s√≥ o texto
    return await sendBotMessage(sender, resumo);
  },  
  responderDuvida: async (sender, args, extras) => {
    await setUserStage(sender, "agente_de_demonstracao_detalhada");

    const { msgContent, quotedMessage } = extras;

    const entrada = await sanitizarEntradaComQuoted(sender, msgContent, quotedMessage);

    const { modelos, nomeUsuario,  modelosConfirmados, conversaCompleta } = await prepararContextoDeModelosRecentesFluxo(sender);

    if (modelos.length === 0) {
      return await sendBotMessage(sender, "‚ö†Ô∏è Ainda n√£o te mostrei nenhum modelo pra comparar. Quer ver algumas op√ß√µes?");
    }

    // üéØ üí• Aqui entra a corre√ß√£o: se veio nomeModelo no argumento, foque nesse modelo
    const modeloFocado = args?.nomeModelo
      ? modelos.find(m => m.nome.toLowerCase() === args.nomeModelo.toLowerCase())
      : null;

    let descricaoModelos = "";

    if (modeloFocado) {
      descricaoModelos = `
  ‚û°Ô∏è *${modeloFocado.nome}*
  üí¨ Descri√ß√£o: ${modeloFocado.descricaoCurta}
  üß† Subt√≠tulo: ${modeloFocado.subTitulo}
  üí° Frase impacto: ${modeloFocado.fraseImpacto}
  üíµ Pre√ßo: R$ ${modeloFocado.preco.toFixed(2)}
  üí≥ Parcelado: ${modeloFocado.precoParcelado}
  üñºÔ∏è Imagem: ${modeloFocado.imagemURL}
  `;
    } else {
      descricaoModelos = modelos.map(m => `
  ‚û°Ô∏è *${m.nome}*
  üí¨ Descri√ß√£o: ${m.descricaoCurta}
  üß† Subt√≠tulo: ${m.subTitulo}
  üí° Frase impacto: ${m.fraseImpacto}
  üíµ Pre√ßo: R$ ${m.preco.toFixed(2)}
  üí≥ Parcelado: ${m.precoParcelado}
  üñºÔ∏è Imagem: ${m.imagemURL}
  `).join("\n");
    }


    const contexto = `
    Voc√™ √© Anna, especialista da Vertex Store.
    
    Siga exatamente as diretrizes abaixo para responder qualquer cliente:
    
    TOM DE VOZ:
    ${JSON.stringify(tomDeVozVertex, null, 2)}
    
    OBJE√á√ïES COMUNS:
    ${JSON.stringify(obje√ß√µesVertex, null, 2).slice(0, 3000)}     
    
    GATILHOS EMOCIONAIS:
    ${JSON.stringify(gatilhosEmocionaisVertex, null, 2)}
    `;

    // üß† Prompt formatado para a IA
    const prompt = `
  ## OBJETIVO
  Guiar o cliente at√© escolher um smartphone da lista apresentada e fechar a venda,
  sempre valorizando experi√™ncia, suporte humanizado e diferencial da loja.
  esteja sempre preparado para responder duvidas de obje√ß√µes que n√£o necessariamente ligados ao modelo em si, utlize a documenta√ß√£o para respoder essa obje√ß√µes e seja criativo
  *** SEMPRE AO FALAR DE PRE√áOS DEIXE BEM CLARO QUE ESSE VALORES S√ÉO ESTIMATIVAS E QUE PODEM FLUTUAR DE ACORDO COM A DISPONIBILIDADE DA PAY JOY ***
  ## TOM_DE_VOZ
  - Sauda√ß√£o acolhedora por√©m direta.
  - Use vocativo informal respeitoso (ex.: ‚ÄúPerfeito, ${nomeUsuario}!‚Äù).
  - Emojis: üíú obrigat√≥rio + 1 contextual; use üî• para descontos.
  - At√© 250 caracteres por bloco; quebre linhas por assunto.
  - Pontua√ß√£o dupla (‚Äú!!‚Äù, ‚Äú‚Ä¶‚Äù ) permitida.

  ## GATILHOS_EMOCIONAIS
  - Priorize Seguran√ßa ‚ûú Rapidez ‚ûú Transfer√™ncia de dados na hora.
  - Explore ‚ÄúGarantia emp√°tica‚Äù, ‚ÄúTelefone reserva‚Äù, ‚ÄúLoja f√≠sica confi√°vel‚Äù.
  - Conecte benef√≠cios √† vida di√°ria (produtividade, mem√≥rias, status).

  ## OBJE√á√ïES & COMPARATIVOS
  - Se cliente comparar pre√ßo online ‚Üí explique valor agregado (lista de diferenciais).
  - Descontos: no boleto n√£o descontos
  - Parcelamento padr√£o apenas em 18√ó somente parcelamos em 18x; .
  - Use analogias para comparar servi√ßos (ex.: ‚Äúcomprar s√≥ pre√ßo √© como‚Ä¶‚Äù).  
  
  ## REGRAS_DE_INDECIS√ÉO
- Em caso de d√∫vida ou indecis√£o, atue como consultor confi√°vel, trazendo clareza e seguran√ßa.
- Reforce os diferenciais da Vertex:
  Pronta entrega üí® | P√≥s-venda humanizado üíú | Garantia local | Teste/backup na hora üîßüì≤
- Use perguntas abertas para desbloquear a decis√£o:
  - ‚ÄúQual parte voc√™ quer que eu explique melhor?‚Äù
  - ‚ÄúEst√° comparando com outro modelo ou loja?‚Äù
- Ofere√ßa ajuda direta:
  - ‚ÄúQuer que eu compare dois modelos pra facilitar?‚Äù
  - ‚ÄúPrefere decidir por c√¢mera, bateria ou desempenho?‚Äù
- Finalize com call-to-action leve:
  - ‚ÄúQuer que eu mostre o resumo e voc√™ decide com calma?‚Äù
- Quando a indecis√£o n√£o for tecnica de aparelho nem sobre valores
  - "responda com criatividade em cima da obje√ß√£o"

  ## REGRAS_DE_ESTILO
  - Nunca comece com sauda√ß√£o completa; a conversa j√° est√° em andamento.
  - Seja conciso e humanizado; m√°ximo 3 blocos (‚Äúemo√ß√£o‚Äù, ‚Äúbenef√≠cio‚Äù, ‚Äúcall-to-action‚Äù).
  - Sempre feche perguntando algo que avance (ex.: ‚ÄúFecho em 10√ó pra voc√™?‚Äù).

   "localizacaoLoja":  
      "endereco": "Av. Get√∫lio Varga, 333, Centro, Araruama - RJ, Brasil. CEP 28979-129",
      "referencia": "Mesma cal√ßada da loteria e xerox do bol√£o, em frente √† faixa de pedestre",
      "horarioFuncionamento": "De 09:00 √†s 19:00, de segunda a s√°bado"

  üìú Hist√≥rico da conversa:
        ${conversaCompleta}
      
      üß† √öltima mensagem do cliente:
      "${entrada}"
      
      üì± Modelos apresentados:
      ${modelos.map(m => `‚û°Ô∏è *${m.nome}*\nüìù ${m.descricaoCurta}\nüíµ Pre√ßo: R$ ${m.preco.toFixed(2)}`).join("\n")}
      
      Nome do cliente: ${nomeUsuario}
      
      ‚úÖ Modelos confirmados anteriormente pelo cliente:
      ${modelosConfirmados.length > 0
        ? modelosConfirmados.map(m => `‚úîÔ∏è *${m}*`).join("\n")
        : "Nenhum ainda foi confirmado."}
      
      üß† √öltimo modelo confirmado:
      ${modelosConfirmados[modelosConfirmados.length - 1] || "nenhum"}
  `;

    const respostaIA = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: contexto },
        { role: "user", content: prompt }
      ],
      temperature: 1.0,
      max_tokens: 200
    });

    const respostaFinal = respostaIA.choices[0]?.message?.content?.trim();

    if (!respostaFinal) {
      return await sendBotMessage(sender, "üìå Estou verificando... Pode repetir a d√∫vida de forma diferente?");
    }

    return await sendBotMessage(sender, respostaFinal);
  },
  responderDuvidasGenericas: async (sender, args, extras) => {
    await setUserStage(sender, "agente_de_demonstracao_detalhada");
    const { msgContent, quotedMessage, pushName } = extras;
    const nomeUsuario = pushName || "cliente";
  
    // üßº Entrada enriquecida com texto do quoted
    const entrada = await sanitizarEntradaComQuoted(sender, msgContent, quotedMessage);
  
    // ‚è∫Ô∏è Salva como d√∫vida geral
    await appendToConversation(sender, {
      tipo: "duvida_geral",
      conteudo: entrada,
      timestamp: new Date().toISOString()
    });
  
    // üìö Carrega o contexto completo da conversa
    const {
      modelos,
      nomeUsuario: nomeUsuarioContextual,
      conversaCompleta,
      modelosConfirmados
    } = await prepararContextoDeModelosRecentesFluxo(sender);
  
    const prompt = `
  Voc√™ √© Anna, especialista da Vertex Store üíú
  
  Responda a seguinte d√∫vida do cliente com empatia, clareza e foco em ajudar de forma informal e acolhedora.
  
  üîç Entrada do cliente:
  "${entrada}"
  
  üì¶ Modelos sugeridos:
  ${modelos.length > 0
      ? modelos.map(m => `‚û°Ô∏è ${m.nome} - ${m.descricaoCurta} - R$ ${m.preco.toFixed(2)}`).join("\n")
      : "Nenhum modelo sugerido ainda."}
  
  ‚úîÔ∏è Modelos confirmados:
  ${modelosConfirmados.length > 0
      ? modelosConfirmados.map(m => `‚úîÔ∏è ${m}`).join("\n")
      : "Nenhum confirmado ainda."}
  
  üìú Hist√≥rico recente:
  ${conversaCompleta}
  
  üí° Instru√ß√µes:
  - Se a d√∫vida for sobre produto, pre√ßo, garantia ou suporte ‚Üí responda com clareza.
  - Se for uma d√∫vida fora do escopo (ex: troca, defeito, localiza√ß√£o), oriente e diga que ser√° encaminhada.
  - Use tom humano, emp√°tico, com emoji üíú e uma pergunta no final.

  "localizacaoLoja":  
      "endereco": "Av. Get√∫lio Varga, 333, Centro, Araruama - RJ, Brasil. CEP 28979-129",
      "referencia": "Mesma cal√ßada da loteria e xerox do bol√£o, em frente √† faixa de pedestre",
      "horarioFuncionamento": "De 09:00 √†s 19:00, de segunda a s√°bado"
  `;
  
    const respostaIA = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: `Voc√™ √© uma atendente da Vertex Store, informal, clara e acolhedora.` },
        { role: "user", content: prompt }
      ],
      temperature: 0.9,
      max_tokens: 350
    });
  
    const respostaFinal = respostaIA.choices?.[0]?.message?.content?.trim();
  
    if (!respostaFinal) {
      return await sendBotMessage(sender, "üì© Recebi sua d√∫vida, e j√° estou vendo com a equipe! J√° te retorno üíú");
    }
  
    return await sendBotMessage(sender, respostaFinal);
  },
  perguntarSobreBoleto: async (sender, args, { pushName, msgContent }) => {  
    await setUserStage(sender, "perguntar_sobre_boleto");
    const nomeUsuario = await getNomeUsuario(sender)
     
    const delay = (ms) => new Promise((resolve) => setTimeout(resolve, ms));
    await delay(2000);
  
    await sendBotMessage(sender, `${nomeUsuario} para vendas no boleto temos modelos e condi√ß√µes diferentes. Me ajuda a entender algumas coisas antes`);
   
    return await rotinaDeBoleto({ sender, msgContent, pushName });
  }

}

 

 
module.exports = {
  agenteDeDemonstracaoDetalhada,
  handlers
};

