// üîÑ Agente GPT completo com l√≥gica igual a identificarModeloPorNome
const { sendBotMessage } = require("../../messageSender");
const {
  setUserStage,
  appendToConversation,
  getConversation,
  getNomeUsuario,
  getUserStage,
} = require("../../redisService");
const { getAllCelulares } = require("../../dbService");
const { rotinaDeAgendamento } = require("../../GerenciadorDeRotinas/GerenciadorDeAgendamento/rotinaDeAgendamento");
const OpenAI = require("openai");
require("dotenv").config();
const { obje√ß√µesVertex } = require("../../../Services/utils/objecoes");
const { gatilhosEmocionaisVertex } = require('../../../Services/utils/gatilhosEmocionais');
const { tomDeVozVertex } = require('../../../Services/utils/tomDeVozVertex');

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const obterModelosDoBling = async () => {
  const celulares = await getAllCelulares();

  const termosIgnorados = [
    "BLACK", "WHITE", "BLUE", "GREEN", "GOLD", "PURPLE", "SILVER", "CORAL",
    "MIDNIGHT", "OCEAN", "TEAL", "AZUL", "VERDE", "LAVENDER", "VOYAGE",
    "MARBLE", "STORM", "LIGHTNING", "SPARKLE", "DARK", "LIME", "STAR", "STARRY",
    "OC√âANO", "ROM", "RAM"
  ];

  const normalizeNome = (nome) =>
    nome
      .replace(/^smartphone\s*/i, "")
      .replace(/[^\w\s]/gi, "")
      .trim()
      .split(/\s+/)
      .filter((p) => !termosIgnorados.includes(p.toUpperCase()))
      .join(" ")
      .toLowerCase()
      .trim();

  const mapaUnico = new Map();

  for (const c of celulares) {
    const chave = normalizeNome(c.nome);
    if (!mapaUnico.has(chave)) {
      mapaUnico.set(chave, {
        nome: c.nome,
        preco: c.preco,
        descricaoCurta: c.descricao, // ‚úÖ Corrigido aqui!
        imagemURL: c.imageURL,
        precoParcelado: c.precoParcelado,
        fraseImpacto: c.fraseImpacto,
        subTitulo: c.subTitulo,
        videoURL: c.videoURL,
      });
    }
  }

  return Array.from(mapaUnico.values());
};


const calcularSimilaridadePorEmbeddings = async (entrada, modelos) => {
  const entradaEmbedding = await openai.embeddings.create({ model: "text-embedding-3-small", input: entrada });
  const modelosEmbedding = await openai.embeddings.create({ model: "text-embedding-3-small", input: modelos.map(m => m.nome) });
  const vetorEntrada = entradaEmbedding.data[0].embedding;
  return modelosEmbedding.data.map((item, i) => {
    const m = modelos[i];
    const score = vetorEntrada.reduce((acc, val, idx) => acc + val * item.embedding[idx], 0);
    return { ...m, score };
  }).sort((a, b) => b.score - a.score);
};

const formatarDescricaoParaCaption = (modelo) => (
  `üî• *${modelo.nome}*üî•\n\n${modelo.subTitulo}\n\n${modelo.descricaoCurta}\n\nüí∞üì¶ ${modelo.precoParcelado}\n\n${modelo.fraseImpacto}\n\nüíµ Pre√ßo: R$ ${modelo.preco?.toFixed(2)}`
    .replace(/\u00A0/g, ' ').replace(/\u200B/g, '').replace(/\r/g, '').replace(/[ \t]+\n/g, '\n').replace(/\n[ \t]+/g, '\n').replace(/\n{3,}/g, '\n\n').trim()
);

const agenteDeDemonstracaoDetalhada = async ({ sender, msgContent }) => {
  const nome = await getNomeUsuario(sender);
  try {
    const entradaAtual = typeof msgContent === "string" ? msgContent : msgContent?.termosRelacionados || "";
    await appendToConversation(sender, entradaAtual);
    const conversaArray = await getConversation(sender);
    const conversaCompleta = conversaArray.map(f => f.replace(/^again\s*/i, "").trim()).slice(-10).join(" | ");
    const listaParaPrompt = await obterModelosDoBling();

    const completion = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: `Voc√™ √© Anna. Seu trabalho √© apresentar UM modelo de celular ao cliente com base na lista abaixo. Se identificar o modelo, use mostrarResumoModelo. Se o cliente quiser agendar, use fecharVenda.\n\nHist√≥rico:\n${conversaCompleta}\n\nModelos dispon√≠veis:\n${listaParaPrompt.map(m => `- ${m.nome}`).join("\n")}`
        },
        { role: "user", content: entradaAtual }
      ],
      functions,
      function_call: "auto"
    });

    const toolCall = completion.choices[0]?.message?.function_call;
    if (toolCall) {
      const { name, arguments: argsStr } = toolCall;
      const args = argsStr ? JSON.parse(argsStr) : {};
      if (handlers[name]) {
        const similaridades = await calcularSimilaridadePorEmbeddings(entradaAtual, listaParaPrompt);
        const modeloEscolhido = similaridades[0];
        return await handlers[name](sender, args, { modeloEscolhido, msgContent });
      }
    }

    const similaridades = await calcularSimilaridadePorEmbeddings(entradaAtual, listaParaPrompt);
    const modeloEscolhido = similaridades[0];
    if (modeloEscolhido?.score > 0.9) {
      return await handlers.mostrarResumoModelo(sender, { nomeModelo: modeloEscolhido.nome }, { modeloEscolhido });
    }
    await sendBotMessage(sender, `N√£o consegui identificar o modelo com clareza. Pode repetir o nome por favor?`);
  } catch (err) {
    console.error("Erro no agenteDeDemonstracaoDetalhada:", err);
    await sendBotMessage(sender, `‚ö†Ô∏è Erro ao analisar o modelo. Pode tentar de novo?`);
  }
};

const handlers = {
  fecharVenda: async (sender, args, extras) => {
    const { modeloEscolhido, pushName, msgContent } = extras;
    await sendBotMessage(sender, `üéØ Perfeito! Vamos agendar agora sua visita para garantir seu ${modeloEscolhido.nome}.`);
    return await rotinaDeAgendamento({ sender, msgContent, pushName });
  },
  mostrarResumoModelo: async (sender, args, extras) => {
    let modelo = extras?.modeloEscolhido;
    const normalize = (str) => str.toLowerCase().normalize("NFD").replace(/[\u0300-\u036f]/g, "").replace(/[^\w\s]/gi, '').replace(/\s+/g, ' ').trim();
    if (!modelo && args?.nomeModelo) {
      const lista = await obterModelosDoBling();
      modelo = lista.find(m => normalize(m.nome) === normalize(args.nomeModelo));
    }
    if (!modelo || !modelo.preco) {
      return await sendBotMessage(sender, "‚ùå N√£o consegui identificar esse modelo. Pode tentar novamente?");
    }
    if (modelo.videoURL) {
      await sendBotMessage(sender, {
        videoUrl: modelo.videoURL,
        caption: `üì± Modelo reconhecido: *${modelo.nome}*`
      });
    }
    await sendBotMessage(sender, `üî• *${modelo.nome}* ‚Äì ${modelo.fraseImpacto}\n\n${modelo.descricaoCurta}\n\nüí∞ *Pre√ßo √† vista:* R$ ${modelo.preco.toFixed(2)}\n\nüëâ Quer agendar uma visita pra garantir o seu?`);
  },
  responderDuvida: async (sender, _args, extras) => {
    await setUserStage(sender, "agente_de_demonstra√ß√£o_detalhada");

    const historico = await getConversation(sender);
    const conversaCompleta = historico.map(f => f.replace(/^again\s*/i, "").trim()).slice(-10).join(" | ");
  
    // Carrega todos os modelos dispon√≠veis do banco (com descri√ß√£o completa)
    const modelosBanco = await getAllCelulares();

    const nome = await getNomeUsuario(sender);
  
    // Extrai nomes do hist√≥rico (modelo_sugerido_json ou modelo_sugerido)
    const nomesHistorico = historico
      .filter(m => m.startsWith("modelo_sugerido_json:") || m.startsWith("modelo_sugerido:"))
      .map(m => {
        if (m.startsWith("modelo_sugerido_json:")) {
          try {
            const obj = JSON.parse(m.replace("modelo_sugerido_json: ", ""));
            return obj.nome;
          } catch {
            return null;
          }
        }
        return m.replace("modelo_sugerido: ", "").trim();
      })
      .filter(Boolean);
  
    // Filtra os modelos do banco que est√£o no hist√≥rico
    const modelos = modelosBanco.filter(m =>
      nomesHistorico.some(n => n.toLowerCase() === m.nome.toLowerCase())
    );
  
    if (modelos.length === 0) {
      return await sendBotMessage(sender, "‚ö†Ô∏è Ainda n√£o te mostrei nenhum modelo pra comparar. Quer ver algumas op√ß√µes?");
    }
    const contexto = `
    Voc√™ √© Anna, especialista da Vertex Store.
    
    Siga exatamente as diretrizes abaixo para responder qualquer cliente:
    
    TOM DE VOZ:
    ${JSON.stringify(tomDeVozVertex, null, 2)}
    
    OBJE√á√ïES COMUNS:
    ${JSON.stringify(obje√ß√µesVertex, null, 2).slice(0, 3000)}
    
    GATILHOS EMOCIONAIS:
    ${JSON.stringify(gatilhosEmocionaisVertex, null, 2)}
    `;
    
    const prompt = `
   ##  OBJETIVO
Guiar o cliente at√© escolher um smartphone da lista apresentada e fechar a venda,
sempre valorizando experi√™ncia, suporte humanizado e diferencial da loja.

##  TOM_DE_VOZ (tomDeVozVertex)
- Sauda√ß√£o acolhedora por√©m direta.
- Use vocativo informal respeitoso (ex.: ‚ÄúPerfeito, Felipe!‚Äù).
- Emojis: üíú obrigat√≥rio + 1 contextual; use üî• para descontos.
- At√© 250 caracteres por bloco; quebre linhas por assunto.
- Pontua√ß√£o dupla (‚Äú!!‚Äù, ‚Äú‚Ä¶‚Äù ) permitida.

##  GATILHOS_EMOCIONAIS (gatilhosEmocionaisVertex)
- Priorize Seguran√ßa ‚ûú Rapidez ‚ûú Transfer√™ncia de dados na hora.
- Explore ‚ÄúGarantia emp√°tica‚Äù, ‚ÄúTelefone reserva‚Äù, ‚ÄúLoja f√≠sica confi√°vel‚Äù.
- Conecte benef√≠cios √† vida di√°ria (produtividade, mem√≥rias, status).

##  OBJEC√á√ïES & COMPARATIVOS (obje√ß√µesVertex)
- Se cliente comparar pre√ßo online ‚Üí explique valor agregado (lista de diferenciais).
- Descontos: s√≥ R$ 100 √† vista, ofere√ßa **ap√≥s** defender valor.
- Parcelamento padr√£o 10√ó; ofere√ßa 12√ó **apenas se insistir** muito.
- Use analogias para comparar servi√ßos (ex.: ‚Äúcomprar s√≥ pre√ßo √© como‚Ä¶‚Äù).

##  REGRAS_DE_ESTILO
- Nunca comece resposta com sauda√ß√£o completa; a conversa j√° est√° em andamento.
- Seja conciso e humanizado; m√°ximo 3 blocos (‚Äúemo√ß√£o‚Äù, ‚Äúbenef√≠cio‚Äù, ‚Äúcall-to-action‚Äù).
- Sempre feche perguntando algo que avance (ex.: ‚ÄúFecho em 10√ó pra voc√™?‚Äù).
###############################

    üìú Hist√≥rico da conversa:
    ${conversaCompleta}
    
    üì® √öltima mensagem do cliente:
    "${extras.msgContent}"
    
    üì± Modelos apresentados:
    ${modelos.map(m => `‚û°Ô∏è *${m.nome}*\n${m.descricao}\nüíµ Pre√ßo: R$ ${m.preco.toFixed(2)}`).join("\n")}
    
    üí∞ Pre√ßos (para c√°lculo de desconto):
    ${modelos.map(m => `‚Ä¢ ${m.nome}: R$ ${m.preco.toFixed(2)}`).join("\n")}

    Nome do usuario
    ${nome}
    `;   
  
    const respostaIA = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: contexto },  // ‚úÖ system primeiro
        { role: "user", content: prompt }
      ],
      temperature: 1.0,
      max_tokens: 150
    });
  
    const respostaFinal = respostaIA.choices[0]?.message?.content?.trim();
  
    if (!respostaFinal) {
      return await sendBotMessage(sender, "üìå Estou verificando... Pode repetir a d√∫vida de forma diferente?");
    }
  
    return await sendBotMessage(sender, respostaFinal);
  }

}

const functions = [
  {
    name: "fecharVenda",
    description: "Chama o agente de fechamento ap√≥s o resumo e o video terem sido enviados e depois que o cliente quiser comprar ou agendar.",
    parameters: {
      type: "object",
      properties: {
        confirmacao: { type: "string", description: "Inten√ß√£o de compra/agendamento" },
      },
      required: ["confirmacao"],
    },
  },
  {
    name: "mostrarResumoModelo",
    description: "Mostra o v√≠deo e o resumo formatado de um modelo espec√≠fico reconhecido.",
    parameters: {
      type: "object",
      properties: {
        nomeModelo: { type: "string", description: "Nome exato do modelo reconhecido" }
      },
      required: ["nomeModelo"],
    },
  },
  {
    name: "responderDuvida",
    description: "Responde a uma d√∫vida espec√≠fica do cliente sobre um ou mais modelos sugeridos anteriormente.",
    parameters: {
      type: "object",
      properties: {
        resposta: {
          type: "string",
          description: "Texto da resposta explicando diferen√ßas, vantagens ou informa√ß√µes adicionais."
        }
      },
      required: ["resposta"]
    }
  },
];

 
module.exports = {
  agenteDeDemonstracaoDetalhada
  
};

