// ğŸ”„ Agente GPT completo com lÃ³gica igual a identificarModeloPorNome
const { sendBotMessage } = require("../../messageSender");
const {
  setUserStage,
  appendToConversation,
  getConversation,
  getNomeUsuario,
  getUserStage,
} = require("../../redisService");
const { getAllCelulareBoleto } = require("../../dbService");
const { rotinaDeAgendamento } = require("../../GerenciadorDeRotinas/GerenciadorDeAgendamento/rotinaDeAgendamento");
const OpenAI = require("openai");
require("dotenv").config();
const { informacoesPayjoy } = require("../../utils/documentacoes/informacoesPayjoy");
const { gatilhosEmocionaisVertex } = require('../../utils/documentacoes/gatilhosEmocionais');
const { tomDeVozVertex } = require('../../utils/documentacoes/tomDeVozVertex');
const { objeÃ§ÃµesVertexBoleto } = require("../../utils/documentacoes/objecoesBoleto");;
const { tomDeVozVertexData } = require("../../utils/documentacoes/tomDeVozVertexData");
const { extrairTextoDoQuotedMessage } = require("../../utils/utilitariosDeMensagem/extrairTextoDoQuotedMessage");
const { sanitizarEntradaComQuoted } = require("../../utils/utilitariosDeMensagem/sanitizarEntradaComQuoted");
const { prepararContextoDeModelosRecentes } = require("../../utils/utilitariosDeMensagem/prepararContextoDeModelosRecentes");

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const obterModelosDoBling = async () => {
  const celulares = await getAllCelulareBoleto();

  const termosIgnorados = [
    "BLACK", "WHITE", "BLUE", "GREEN", "GOLD", "PURPLE", "SILVER", "CORAL",
    "MIDNIGHT", "OCEAN", "TEAL", "AZUL", "VERDE", "LAVENDER", "VOYAGE",
    "MARBLE", "STORM", "LIGHTNING", "SPARKLE", "DARK", "LIME", "STAR", "STARRY",
    "OCÃ‰ANO", "ROM", "RAM"
  ];

  const normalizeNome = (nome) =>
    nome
      .replace(/^smartphone\s*/i, "")
      .replace(/[^\w\s]/gi, "")
      .trim()
      .split(/\s+/)
      .filter((p) => !termosIgnorados.includes(p.toUpperCase()))
      .join(" ")
      .toLowerCase()
      .trim();

  const mapaUnico = new Map();

  for (const c of celulares) {
    const chave = normalizeNome(c.nome);
    if (!mapaUnico.has(chave)) {
      mapaUnico.set(chave, {
        nome: c.nome,
        preco: c.preco,
        descricaoCurta: c.descricao, // âœ… Corrigido aqui!
        imagemURL: c.imageURL,
        precoParcelado: c.precoParcelado,
        fraseImpacto: c.fraseImpacto,
        subTitulo: c.subTitulo,
        videoURL: c.videoURL,
      });
    }
  }

  return Array.from(mapaUnico.values());
};

const calcularSimilaridadePorEmbeddings = async (entrada, modelos) => {
  const entradaEmbedding = await openai.embeddings.create({ model: "text-embedding-3-small", input: entrada });
  const modelosEmbedding = await openai.embeddings.create({ model: "text-embedding-3-small", input: modelos.map(m => m.nome) });
  const vetorEntrada = entradaEmbedding.data[0].embedding;
  return modelosEmbedding.data.map((item, i) => {
    const m = modelos[i];
    const score = vetorEntrada.reduce((acc, val, idx) => acc + val * item.embedding[idx], 0);
    return { ...m, score };
  }).sort((a, b) => b.score - a.score);
}; 

const agenteDeDemonstracaoDetalhadaBoleto = async ({ sender, msgContent, pushName }) => {
  try {
    await setUserStage(sender, "agente_de_demonstracao_detalhada_boleto");

    const nome = await getNomeUsuario(sender);
    const textoQuoted = extrairTextoDoQuotedMessage(msgContent);

    let entradaAtual = typeof msgContent === "string" ? msgContent : msgContent?.termosRelacionados || "";     

    await appendToConversation(sender, {
      tipo: "entrada_usuario",
      conteudo: entradaAtual,
      timestamp: new Date().toISOString()
    });

    const conversaArray = await getConversation(sender);
    const conversaCompleta = conversaArray
      .map(msg => {
        try {
          const json = typeof msg === "string" ? JSON.parse(msg) : msg;
          return json.conteudo || "";
        } catch {
          return typeof msg === "string" ? msg : "";
        }
      })
      .filter(Boolean)
      .slice(-10)
      .join(" | ");

    const listaModelos = await obterModelosDoBling();

    const similares = await calcularSimilaridadePorEmbeddings(entradaAtual, listaModelos);
    console.log(`Esse foi o match de similaridade${similares}`)
    const maisProvavel = similares?.[0];
    console.log(`Esse foi o match de similaridade${maisProvavel}`)

    if (maisProvavel?.score > 0.90) {
      console.log("âœ… Entrada casa fortemente com modelo:", maisProvavel.modelo);
      await appendToConversation(sender, {
        tipo: "deliberacao_toa",
        conteudo: {
          acao: "mostrarResumoModeloBoleto",
          motivo: `Cliente mencionou ${maisProvavel.modelo} com alta similaridade`,
          argumento: { modeloMencionado: maisProvavel.modelo }
        },
        timestamp: new Date().toISOString()
      });

      return await mostrarResumoModeloBoleto(sender, {
        modeloMencionado: maisProvavel.modelo
      }, { msgContent: entradaAtual });
    }

    const promptTOA = `
ğŸ¤– VocÃª Ã© Anna, assistente virtual da Vertex Store.

Seu objetivo Ã© identificar a aÃ§Ã£o ideal com base na intenÃ§Ã£o do cliente.

ğŸ“Œ Entrada:
"${entradaAtual}"

ğŸ“œ HistÃ³rico da conversa:
${conversaCompleta}

ğŸ“¦ Modelos disponÃ­veis:
${listaModelos.map(m => `- ${m.nome}`).join("\n")}

1. **fecharVenda** â†’ quando estiver decidido ou indicar desejo de finalizar, mesmo que sem palavras exatas como "fechou". Ex: â€œgostei muito desseâ€, â€œacho que vou aÃ­ amanhÃ£â€, â€œvamos ver esse aÃ­â€.

âš ï¸ SÃ³ escolha "fecharVenda" se jÃ¡ houver uma execuÃ§Ã£o anterior da aÃ§Ã£o "mostrarResumoModeloBoleto" com o modelo confirmado. Passe o modelo com argumento

2. Se o cliente fizer **qualquer pergunta**, mesmo curta (ex.: "Ã© bom?", "qual o preÃ§o?", "tem cÃ¢mera boa?"), isso significa que ele ainda estÃ¡ com dÃºvida e precisa de mais informaÃ§Ãµes. Escolha "responderDuvida".

âš ï¸ SE o cliente mencionar claramente um modelo (ex: "o note 60 Ã© bom?"), vocÃª DEVE preencher o campo "argumento.nomeModelo" com o nome exato do modelo mencionado.

3. Se ele mencionar um modelo da lista e nÃ£o for uma pergunta, escolha "mostrarResumoModeloBoleto".

âš ï¸ Quando escolher "mostrarResumoModeloBoleto" vocÃª tambÃ©m DEVE preencher "argumento.nomeModelo" com o nome exato do modelo citado.

 4. Se a mensagem do cliente **nÃ£o mencionar nenhum modelo**,  
e a dÃºvida parecer geral, filosÃ³fica, comportamental ou fora do escopo dos modelos â€”  
ex: "vocÃªs vendem usados?", "e se der defeito?", "vocÃªs tem loja fÃ­sica?",  
"qual Ã© o diferencial de vocÃªs?", "vocÃªs sÃ£o confiÃ¡veis?", "aceitam cartÃ£o?"  
â€” entÃ£o entenda que Ã© uma dÃºvida genÃ©rica.  
Escolha: **"responderDuvidasGenericas"**

Retorne apenas isso:
{
  "acao": "NOME_DA_ACAO",
  "motivo": "Texto explicando por que esta aÃ§Ã£o foi escolhida",
  "argumento": {}
}`;

    const deliberacao = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [{ role: "user", content: promptTOA }],
      temperature: 0.8
    });

    const jsonMatch = deliberacao.choices?.[0]?.message?.content?.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      console.error("âŒ TOA nÃ£o retornou JSON vÃ¡lido.");
      return await sendBotMessage(sender, "âš ï¸ NÃ£o consegui entender sua escolha. Pode repetir?");
    }    

    const { acao, motivo, argumento } = JSON.parse(jsonMatch[0]);

    console.log("ğŸ§  TOA escolheu:", acao, "â†’", motivo);

    await appendToConversation(sender, {
      tipo: "deliberacao_toa",
      conteudo: { acao, motivo, argumento },
      timestamp: new Date().toISOString()
    });

    if (!handlers[acao]) {
      return await sendBotMessage(sender, "âš ï¸ NÃ£o entendi sua intenÃ§Ã£o. Pode repetir?");
    }

    return await handlers[acao](sender, argumento, { msgContent: entradaAtual });

  } catch (error) {
    console.error("âŒ Erro no agenteDeDemonstracaoDetalhadaBoleto:", error);
    return await sendBotMessage(sender, "âš ï¸ Ocorreu um erro. Pode tentar de novo?");
  }
};

const handlers = {
  fecharVenda: async (sender, _args, extras) => {
    const { modeloEscolhido, pushName, msgContent } = extras;
    return await rotinaDeAgendamento({ sender, msgContent, pushName });
  },
  mostrarResumoModeloBoleto: async (sender, args, extras) => {
    await setUserStage(sender, "agente_de_demonstracao_detalhada_boleto");
  
    const nome = await getNomeUsuario(sender);
    let modelo = extras?.modeloEscolhido;
  
    const normalize = (str) =>
      str
        .toLowerCase()
        .normalize("NFD")
        .replace(/[\u0300-\u036f]/g, "")
        .replace(/[^\w\s]/gi, "")
        .replace(/\s+/g, " ")
        .trim();
  
    const listaModelos = await obterModelosDoBling();
  
    // ğŸ” Se nÃ£o veio modelo direto, tenta pelo nome passado como argumento
    if (!modelo && args?.nomeModelo) {
      modelo = listaModelos.find(m => normalize(m.nome) === normalize(args.nomeModelo));
    }
  
    // ğŸ” Fallback: tenta recuperar do histÃ³rico
    if (!modelo) {
      const historico = await getConversation(sender);
      const confirmados = historico
        .filter(m => m.tipo === "modelo_confirmado")
        .map(m => typeof m.conteudo === "string" ? m.conteudo : "")
        .filter(Boolean);
  
      // âš ï¸ Se houver mais de um modelo confirmado, pede escolha explÃ­cita
      if (confirmados.length > 1) {
        return await sendBotMessage(sender, `ğŸ“Œ Perfeito, ${nome}! Conversamos sobre mais de um modelo.\nPode me dizer qual deles vocÃª quer ver agora?`);
      }
  
      // âœ… Se houver apenas um, tenta localizar no catÃ¡logo
      if (confirmados.length === 1) {
        const confirmado = confirmados[0];
        modelo = listaModelos.find(m => normalize(m.nome) === normalize(confirmado));
      }
    }
  
    if (!modelo) {
      return await sendBotMessage(sender, `âš ï¸ Opa ${nome}, nÃ£o consegui identificar com clareza o modelo que vocÃª quer ver.\nPode me dizer o nome exato?`);
    }
  
    // ğŸ“¦ Prompt resumido para IA gerar o pitch do modelo
    const prompt = [
      {
        role: "system",
        content: `VocÃª Ã© um vendedor persuasivo e direto. 
  Seja direto, com no mÃ¡ximo 3 frases curtas. Priorize clareza e impacto, nÃ£o ultrapasse 250 caracteres no total.
  
  ***FaÃ§a o mais resumido possÃ­vel para economizar tokens***
  Use uma linguagem formal mas descontraÃ­da.
  Pule uma linha entre o resumo e o tom de voz.
  DÃª preferÃªncia ao preÃ§o parcelado.
  
  Nome do cliente: ${nome}
  
  Ao final, sempre faÃ§a perguntas utilizando esse documento como base:
  TOM DE VOZ:
  ${JSON.stringify(tomDeVozVertexData, null, 2)}`
      },
      {
        role: "user",
        content: `Modelo: ${modelo.nome}
        Frase de impacto: ${modelo.fraseImpacto}
        DescriÃ§Ã£o curta: ${modelo.descricaoCurta}
        PreÃ§o Ã  vista: R$ ${modelo.preco.toFixed(2)}
        PreÃ§o parcelado: ${modelo.precoParcelado || "consulte condiÃ§Ãµes"}`
              }
    ];
  
    let resumo = "";
    try {
      const resposta = await openai.chat.completions.create({
        model: "gpt-4",
        messages: prompt,
        temperature: 0.99,
        max_tokens: 150
      });
  
      resumo = resposta.choices?.[0]?.message?.content?.trim() || "";
    } catch (err) {
      console.error("âŒ Erro ao gerar resumo com GPT:", err);
      resumo = `ğŸ“± *${modelo.nome}*\n${modelo.fraseImpacto}\nğŸ’° R$ ${modelo.preco.toFixed(2)}\n\nEm breve te explico mais!`;
    }
  
    // ğŸ’¾ Salva modelo no histÃ³rico
    await appendToConversation(sender, {
      tipo: "modelo_sugerido_json",
      conteudo: modelo,
      timestamp: new Date().toISOString()
    });

    // ğŸ’¾ Salva tambÃ©m como modelo confirmado (para referÃªncia futura)
await appendToConversation(sender, {
  tipo: "modelo_confirmado",
  conteudo: modelo.nome,
  timestamp: new Date().toISOString()
});

  
    // ğŸ“¹ Envia o vÃ­deo com resumo na legenda
    if (modelo.videoURL) {
      return await sendBotMessage(sender, {
        videoUrl: modelo.videoURL,
        caption: resumo
      });
    }
  
    // ğŸ“„ Se nÃ£o tiver vÃ­deo, envia sÃ³ o texto
    return await sendBotMessage(sender, resumo);
  },  
  responderDuvida: async (sender, args, extras) => {
    await setUserStage(sender, "agente_de_demonstracao_detalhada_boleto");

    const { msgContent, quotedMessage } = extras;

    const entrada = await sanitizarEntradaComQuoted(sender, msgContent, quotedMessage);

    const { modelos, nomeUsuario,  modelosConfirmados, conversaCompleta } = await prepararContextoDeModelosRecentes(sender);

    if (modelos.length === 0) {
      return await sendBotMessage(sender, "âš ï¸ Ainda nÃ£o te mostrei nenhum modelo pra comparar. Quer ver algumas opÃ§Ãµes?");
    }

    // ğŸ¯ ğŸ’¥ Aqui entra a correÃ§Ã£o: se veio nomeModelo no argumento, foque nesse modelo
    const modeloFocado = args?.nomeModelo
      ? modelos.find(m => m.nome.toLowerCase() === args.nomeModelo.toLowerCase())
      : null;

    let descricaoModelos = "";

    if (modeloFocado) {
      descricaoModelos = `
  â¡ï¸ *${modeloFocado.nome}*
  ğŸ’¬ DescriÃ§Ã£o: ${modeloFocado.descricaoCurta}
  ğŸ§  SubtÃ­tulo: ${modeloFocado.subTitulo}
  ğŸ’¡ Frase impacto: ${modeloFocado.fraseImpacto}
  ğŸ’µ PreÃ§o: R$ ${modeloFocado.preco.toFixed(2)}
  ğŸ’³ Parcelado: ${modeloFocado.precoParcelado}
  ğŸ–¼ï¸ Imagem: ${modeloFocado.imagemURL}
  `;
    } else {
      descricaoModelos = modelos.map(m => `
  â¡ï¸ *${m.nome}*
  ğŸ’¬ DescriÃ§Ã£o: ${m.descricaoCurta}
  ğŸ§  SubtÃ­tulo: ${m.subTitulo}
  ğŸ’¡ Frase impacto: ${m.fraseImpacto}
  ğŸ’µ PreÃ§o: R$ ${m.preco.toFixed(2)}
  ğŸ’³ Parcelado: ${m.precoParcelado}
  ğŸ–¼ï¸ Imagem: ${m.imagemURL}
  `).join("\n");
    }


    const contexto = `
    VocÃª Ã© Anna, especialista da Vertex Store.
    
    Siga exatamente as diretrizes abaixo para responder qualquer cliente:
    
    TOM DE VOZ:
    ${JSON.stringify(tomDeVozVertex, null, 2)}
    
    OBJEÃ‡Ã•ES COMUNS:
    ${JSON.stringify(objeÃ§ÃµesVertexBoleto, null, 2).slice(0, 3000)}

       OBJEÃ‡Ã•ES SOBRE PAYJOY:
    ${JSON.stringify(informacoesPayjoy).slice(0, 3500)}
    
    GATILHOS EMOCIONAIS:
    ${JSON.stringify(gatilhosEmocionaisVertex, null, 2)}
    `;

    // ğŸ§  Prompt formatado para a IA
    const prompt = `
  ## OBJETIVO
  Guiar o cliente atÃ© escolher um smartphone da lista apresentada e fechar a venda,
  sempre valorizando experiÃªncia, suporte humanizado e diferencial da loja.
  esteja sempre preparado para responder duvidas de objeÃ§Ãµes que nÃ£o necessariamente ligados ao modelo em si, utlize a documentaÃ§Ã£o para respoder essa objeÃ§Ãµes e seja criativo
  *** SEMPRE AO FALAR DE PREÃ‡OS DEIXE BEM CLARO QUE ESSE VALORES SÃƒO ESTIMATIVAS E QUE PODEM FLUTUAR DE ACORDO COM A DISPONIBILIDADE DA PAY JOY ***
  ## TOM_DE_VOZ
  - SaudaÃ§Ã£o acolhedora porÃ©m direta.
  - Use vocativo informal respeitoso (ex.: â€œPerfeito, ${nomeUsuario}!â€).
  - Emojis: ğŸ’œ obrigatÃ³rio + 1 contextual; use ğŸ”¥ para descontos.
  - AtÃ© 250 caracteres por bloco; quebre linhas por assunto.
  - PontuaÃ§Ã£o dupla (â€œ!!â€, â€œâ€¦â€ ) permitida.

  ## GATILHOS_EMOCIONAIS
  - Priorize SeguranÃ§a âœ Rapidez âœ TransferÃªncia de dados na hora.
  - Explore â€œGarantia empÃ¡ticaâ€, â€œTelefone reservaâ€, â€œLoja fÃ­sica confiÃ¡velâ€.
  - Conecte benefÃ­cios Ã  vida diÃ¡ria (produtividade, memÃ³rias, status).

  ## OBJEÃ‡Ã•ES & COMPARATIVOS
  - Se cliente comparar preÃ§o online â†’ explique valor agregado (lista de diferenciais).
  - Descontos: no boleto nÃ£o descontos
  - Parcelamento padrÃ£o apenas em 18Ã— somente parcelamos em 18x; .
  - Use analogias para comparar serviÃ§os (ex.: â€œcomprar sÃ³ preÃ§o Ã© comoâ€¦â€).

   ## OBJEÃ‡Ã•ES DE DUVIDAS SOBRE BOLETO(OBJEÃ‡Ã•ES SOBRE PAYJOY:)

   ## REGRAS_DE_INDECISÃƒO
- Em caso de dÃºvida ou indecisÃ£o, atue como consultor confiÃ¡vel, trazendo clareza e seguranÃ§a.
- Reforce os diferenciais da Vertex:
  Pronta entrega ğŸ’¨ | PÃ³s-venda humanizado ğŸ’œ | Garantia local | Teste/backup na hora ğŸ”§ğŸ“²
- Use perguntas abertas para desbloquear a decisÃ£o:
  - â€œQual parte vocÃª quer que eu explique melhor?â€
  - â€œEstÃ¡ comparando com outro modelo ou loja?â€
- OfereÃ§a ajuda direta:
  - â€œQuer que eu compare dois modelos pra facilitar?â€
  - â€œPrefere decidir por cÃ¢mera, bateria ou desempenho?â€
- Finalize com call-to-action leve:
  - â€œQuer que eu mostre o resumo e vocÃª decide com calma?â€
- Quando a indecisÃ£o nÃ£o for tecnica de aparelho nem sobre valores
  - "responda com criatividade em cima da objeÃ§Ã£o"

  ## REGRAS_DE_ESTILO
  - Nunca comece com saudaÃ§Ã£o completa; a conversa jÃ¡ estÃ¡ em andamento.
  - Seja conciso e humanizado; mÃ¡ximo 3 blocos (â€œemoÃ§Ã£oâ€, â€œbenefÃ­cioâ€, â€œcall-to-actionâ€).
  - Sempre feche perguntando algo que avance (ex.: â€œFecho em 10Ã— pra vocÃª?â€).

   "localizacaoLoja": 
      "endereco": "Av. GetÃºlio Varga, 333, Centro, Araruama - RJ, Brasil. CEP 28979-129",
      "referencia": "Mesma calÃ§ada da loteria e xerox do bolÃ£o, em frente Ã  faixa de pedestre",
      "horarioFuncionamento": "De 09:00 Ã s 19:00, de segunda a sÃ¡bado"

  ğŸ“œ HistÃ³rico da conversa:
        ${conversaCompleta}
      
      ğŸ§  Ãšltima mensagem do cliente:
      "${entrada}"
      
      ğŸ“± Modelos apresentados:
      ${modelos.map(m => `â¡ï¸ *${m.nome}*\nğŸ“ ${m.descricaoCurta}\nğŸ’µ PreÃ§o: R$ ${m.preco.toFixed(2)}`).join("\n")}
      
      Nome do cliente: ${nomeUsuario}
      
      âœ… Modelos confirmados anteriormente pelo cliente:
      ${modelosConfirmados.length > 0
        ? modelosConfirmados.map(m => `âœ”ï¸ *${m}*`).join("\n")
        : "Nenhum ainda foi confirmado."}
      
      ğŸ§  Ãšltimo modelo confirmado:
      ${modelosConfirmados[modelosConfirmados.length - 1] || "nenhum"}
  `;

    const respostaIA = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: contexto },
        { role: "user", content: prompt }
      ],
      temperature: 1.0,
      max_tokens: 200
    });

    const respostaFinal = respostaIA.choices[0]?.message?.content?.trim();

    if (!respostaFinal) {
      return await sendBotMessage(sender, "ğŸ“Œ Estou verificando... Pode repetir a dÃºvida de forma diferente?");
    }

    return await sendBotMessage(sender, respostaFinal);
  },
   responderDuvidasGenericas: async (sender, args, extras) => {
      await setUserStage(sender, "agente_de_demonstracao_detalhada_boleto");
      const { msgContent, quotedMessage, pushName } = extras;
      const nomeUsuario = pushName || "cliente";
    
      // ğŸ§¼ Entrada enriquecida com texto do quoted
      const entrada = await sanitizarEntradaComQuoted(sender, msgContent, quotedMessage);
    
      // âºï¸ Salva como dÃºvida geral
      await appendToConversation(sender, {
        tipo: "duvida_geral",
        conteudo: entrada,
        timestamp: new Date().toISOString()
      });
    
      // ğŸ“š Carrega o contexto completo da conversa
      const {
        modelos,
        nomeUsuario: nomeUsuarioContextual,
        conversaCompleta,
        modelosConfirmados
      } = await prepararContextoDeModelosRecentes(sender);
    
      const prompt = `
    VocÃª Ã© Anna, especialista da Vertex Store ğŸ’œ
    
    Responda a seguinte dÃºvida do cliente com empatia, clareza e foco em ajudar de forma informal e acolhedora.
    
    ğŸ” Entrada do cliente:
    "${entrada}"
    
    ğŸ“¦ Modelos sugeridos:
    ${modelos.length > 0
        ? modelos.map(m => `â¡ï¸ ${m.nome} - ${m.descricaoCurta} - R$ ${m.preco.toFixed(2)}`).join("\n")
        : "Nenhum modelo sugerido ainda."}
    
    âœ”ï¸ Modelos confirmados:
    ${modelosConfirmados.length > 0
        ? modelosConfirmados.map(m => `âœ”ï¸ ${m}`).join("\n")
        : "Nenhum confirmado ainda."}
    
    ğŸ“œ HistÃ³rico recente:
    ${conversaCompleta}
    
    ğŸ’¡ InstruÃ§Ãµes:
    - Se a dÃºvida for sobre produto, preÃ§o, garantia ou suporte â†’ responda com clareza.
    - Se for uma dÃºvida fora do escopo (ex: troca, defeito, localizaÃ§Ã£o), oriente e diga que serÃ¡ encaminhada.
    - Use tom humano, empÃ¡tico, com emoji ğŸ’œ e uma pergunta no final.
  
    "localizacaoLoja":  
        "endereco": "Av. GetÃºlio Varga, 333, Centro, Araruama - RJ, Brasil. CEP 28979-129",
        "referencia": "Mesma calÃ§ada da loteria e xerox do bolÃ£o, em frente Ã  faixa de pedestre",
        "horarioFuncionamento": "De 09:00 Ã s 19:00, de segunda a sÃ¡bado"
    `;
    
      const respostaIA = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [
          { role: "system", content: `VocÃª Ã© uma atendente da Vertex Store, informal, clara e acolhedora.` },
          { role: "user", content: prompt }
        ],
        temperature: 0.9,
        max_tokens: 350
      });
    
      const respostaFinal = respostaIA.choices?.[0]?.message?.content?.trim();
    
      if (!respostaFinal) {
        return await sendBotMessage(sender, "ğŸ“© Recebi sua dÃºvida, e jÃ¡ estou vendo com a equipe! JÃ¡ te retorno ğŸ’œ");
      }
    
      return await sendBotMessage(sender, respostaFinal);
    },

}

 
module.exports = {
  agenteDeDemonstracaoDetalhadaBoleto,
  handlers
  
};

