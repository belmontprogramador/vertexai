// üîÑ Agente GPT completo com l√≥gica igual a identificarModeloPorNome
const { sendBotMessage } = require("../../messageSender");
const {
  setUserStage,
  appendToConversation,
  getConversation,
  getNomeUsuario,
  getUserStage,
} = require("../../redisService");
const {getAllCelulareBoleto } = require("../../dbService");
const { rotinaDeAgendamento } = require("../../GerenciadorDeRotinas/GerenciadorDeAgendamento/rotinaDeAgendamento");
const OpenAI = require("openai");
require("dotenv").config();
const { obje√ß√µesVertex } = require("../../../Services/utils/objecoes");
const { gatilhosEmocionaisVertex } = require('../../../Services/utils/gatilhosEmocionais'); 
const { intencaoDataEntregaDesconto } = require('../../../Services/utils/intencaoDataEntregaDesconto');
const { tomDeVozVertexData } = require("../../utils/tomDeVozVertexData");
const { extrairTextoDoQuotedMessage } = require("../../utils/extrairTextoDoQuotedMessage");

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const obterModelosDoBling = async () => {
  const celulares = await getAllCelulareBoleto();

  const termosIgnorados = [
    "BLACK", "WHITE", "BLUE", "GREEN", "GOLD", "PURPLE", "SILVER", "CORAL",
    "MIDNIGHT", "OCEAN", "TEAL", "AZUL", "VERDE", "LAVENDER", "VOYAGE",
    "MARBLE", "STORM", "LIGHTNING", "SPARKLE", "DARK", "LIME", "STAR", "STARRY",
    "OC√âANO", "ROM", "RAM"
  ];

  const normalizeNome = (nome) =>
    nome
      .replace(/^smartphone\s*/i, "")
      .replace(/[^\w\s]/gi, "")
      .trim()
      .split(/\s+/)
      .filter((p) => !termosIgnorados.includes(p.toUpperCase()))
      .join(" ")
      .toLowerCase()
      .trim();

  const mapaUnico = new Map();

  for (const c of celulares) {
    const chave = normalizeNome(c.nome);
    if (!mapaUnico.has(chave)) {
      mapaUnico.set(chave, {
        nome: c.nome,
        preco: c.preco,
        descricaoCurta: c.descricao, // ‚úÖ Corrigido aqui!
        imagemURL: c.imageURL,
        precoParcelado: c.precoParcelado,
        fraseImpacto: c.fraseImpacto,
        subTitulo: c.subTitulo,
        videoURL: c.videoURL,
      });
    }
  }

  return Array.from(mapaUnico.values());
};


const calcularSimilaridadePorEmbeddings = async (entrada, modelos) => {
  const entradaEmbedding = await openai.embeddings.create({ model: "text-embedding-3-small", input: entrada });
  const modelosEmbedding = await openai.embeddings.create({ model: "text-embedding-3-small", input: modelos.map(m => m.nome) });
  const vetorEntrada = entradaEmbedding.data[0].embedding;
  return modelosEmbedding.data.map((item, i) => {
    const m = modelos[i];
    const score = vetorEntrada.reduce((acc, val, idx) => acc + val * item.embedding[idx], 0);
    return { ...m, score };
  }).sort((a, b) => b.score - a.score);
};

const formatarDescricaoParaCaption = (modelo) => (
  `üî• *${modelo.nome}*üî•\n\n${modelo.subTitulo}\n\n${modelo.descricaoCurta}\n\nüí∞üì¶ ${modelo.precoParcelado}\n\n${modelo.fraseImpacto}\n\nüíµ Pre√ßo: R$ ${modelo.preco?.toFixed(2)}`
    .replace(/\u00A0/g, ' ').replace(/\u200B/g, '').replace(/\r/g, '').replace(/[ \t]+\n/g, '\n').replace(/\n[ \t]+/g, '\n').replace(/\n{3,}/g, '\n\n').trim()
);

const agenteDeDemonstracaoDetalhadaBoleto = async ({ sender, msgContent }) => {
  const nome = await getNomeUsuario(sender);
  try {
    // üß† Captura a mensagem citada, se houver
    const textoQuoted = extrairTextoDoQuotedMessage(msgContent);

    // üî§ Normaliza a entrada atual
    let entradaAtual = typeof msgContent === "string" ? msgContent : msgContent?.termosRelacionados || "";

    // üß© Substitui por mensagem citada se for vaga ou indicar "esse"
    if ((!entradaAtual || entradaAtual.toLowerCase().includes("esse")) && textoQuoted) {
      entradaAtual = textoQuoted;
    }

    await appendToConversation(sender, entradaAtual);
    const conversaArray = await getConversation(sender);
    const conversaCompleta = conversaArray.map(f => f.replace(/^again\s*/i, "").trim()).slice(-10).join(" | ");
    const listaParaPrompt = await obterModelosDoBling();

    const completion = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: `
    Voc√™ √© Anna, especialista da Vertex Store.
    
    Seu papel √©: 
    - Sempre sempre Mostrar primeiro o resumo e v√≠deo de UM modelo se o cliente demonstrar interesse direto antes de fechar a venda.
    - Tirar d√∫vidas se ele fizer perguntas espec√≠ficas (como "a bateria √© boa?").
    - Fechar a venda se ele demonstrar inten√ß√£o clara de compra.
    
    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê CONTEXTO DO CLIENTE ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    üìú Hist√≥rico:
    ${conversaCompleta}
    
    üì¶ Modelos dispon√≠veis:
    ${listaParaPrompt.map(m => `- ${m.nome}`).join("\n")}
    
    Lembre-se:
    ‚Ä¢ S√≥ use fun√ß√µes.
    ‚Ä¢ N√£o repita um resumo se o cliente estiver fazendo uma pergunta.
    ‚Ä¢ Sempre prefira tirar d√∫vida se houver incerteza antes de fechar.
    `
        },
        { role: "user", content: entradaAtual }
      ],
      functions,
      function_call: "auto"
    });
    
    const toolCall = completion.choices[0]?.message?.function_call;
   if (toolCall) {
  const { name, arguments: argsStr } = toolCall;
  const args = argsStr ? JSON.parse(argsStr) : {};
  const similaridades = await calcularSimilaridadePorEmbeddings(entradaAtual, listaParaPrompt);
  const modeloEscolhido = similaridades[0];

  if (handlers[name]) {
    return await handlers[name](sender, args, {
      modeloEscolhido,
      msgContent,
      pushName: nome // ou undefined se pushName n√£o for passado aqui
    });
  }
}

    

    const similaridades = await calcularSimilaridadePorEmbeddings(entradaAtual, listaParaPrompt);
    const modeloEscolhido = similaridades[0];
    if (modeloEscolhido?.score > 0.9) {
      return await handlers.mostrarResumoModelo(sender, { nomeModelo: modeloEscolhido.nome }, { modeloEscolhido });
    }
    await sendBotMessage(sender, `N√£o consegui identificar o modelo com clareza. Pode repetir o nome por favor?`);
  } catch (err) {
    console.error("Erro no agenteDeDemonstracaoDetalhada:", err);
    await sendBotMessage(sender, `‚ö†Ô∏è Erro ao analisar o modelo. Pode tentar de novo?`);
  }
};

const handlers = {
  fecharVenda: async (sender, args, extras) => {
    const { modeloEscolhido, pushName, msgContent } = extras;
    return await rotinaDeAgendamento({ sender, msgContent, pushName });
  },
  mostrarResumoModelo: async (sender, args, extras) => {
    let modelo = extras?.modeloEscolhido;
    const nome = await getNomeUsuario(sender);
  
    const normalize = (str) =>
      str.toLowerCase()
        .normalize("NFD")
        .replace(/[\u0300-\u036f]/g, "")
        .replace(/[^\w\s]/gi, "")
        .replace(/\s+/g, " ")
        .trim();
  
    if (!modelo && args?.nomeModelo) {
      const lista = await obterModelosDoBling();
      modelo = lista.find(m => normalize(m.nome) === normalize(args.nomeModelo));
    }
  
    if (!modelo || !modelo.preco) {
      return await sendBotMessage(sender, "‚ùå N√£o consegui identificar esse modelo. Pode tentar novamente?");
    }
  
    // Gera√ß√£o do resumo via GPT
    const prompt = [
      {
        role: "system",
        content: `Voc√™ √© um vendedor persuasivo e direto. 
        Seja direto, com no m√°ximo 3 frases curtas. Priorize clareza e impacto, n√£o ultrapasse 250 caracteres no total.

        ***Fa√ßa o mais resumido possivel para usar o token e n√£o faltar mensagem***
        Use uma linguagem formal mas descontraida.
        pule semre uma linha entre o resumo e a mensagem do tom de voz
        de preferencia ao pre√ßo parcelado
        Nome do cliente ${nome}
        Ao final sempre fa√ßa perguntas utilizando esse documento como base:
        TOM DE VOZ:
        ${JSON.stringify(tomDeVozVertexData, null, 2)}
        
        `
      },
      {
        role: "user",
        content: `Modelo: ${modelo.nome}\nFrase de impacto: ${modelo.fraseImpacto}\nDescri√ß√£o curta: ${modelo.descricaoCurta}\nPre√ßo √† vista: R$ ${modelo.preco.toFixed(2)}`
      }
    ];
  
    let resumo = "";
    try {
      const resposta = await openai.chat.completions.create({
        model: "gpt-4",
        messages: prompt,
        temperature: 0.99,
        max_tokens: 150
      });
  
      resumo = resposta.choices?.[0]?.message?.content?.trim() || "";
    } catch (err) {
      console.error("Erro ao gerar resumo com GPT:", err);
      resumo = `üì± *${modelo.nome}*\n${modelo.fraseImpacto}\nüí∞ R$ ${modelo.preco.toFixed(2)}\n\nEm breve te explico mais!`;
    }  
    
  
    // Envia o v√≠deo com o mesmo resumo como legenda
    if (modelo.videoURL) {
      await sendBotMessage(sender, {
        videoUrl: modelo.videoURL,
        caption: resumo
      });
    }
    
  
    // Salva no hist√≥rico
    await appendToConversation(sender, `modelo_sugerido_json: ${JSON.stringify(modelo)}`);
  },
  responderDuvida: async (sender, _args, extras) => {
    await setUserStage(sender, "agente_de_demonstra√ß√£o_detalhada_boleto");
  
    const historico = await getConversation(sender);
    const conversaCompleta = historico.map(f => f.replace(/^again\s*/i, "").trim()).slice(-10).join(" | ");
    const modelosBanco = await getAllCelulareBoleto();
    const nome = await getNomeUsuario(sender);
  
    const nomesHistorico = historico
      .filter(m => m.startsWith("modelo_sugerido_json:") || m.startsWith("modelo_sugerido:"))
      .map(m => {
        if (m.startsWith("modelo_sugerido_json:")) {
          try {
            const obj = JSON.parse(m.replace("modelo_sugerido_json: ", ""));
            return obj.nome;
          } catch {
            return null;
          }
        }
        return m.replace("modelo_sugerido: ", "").trim();
      })
      .filter(Boolean);
  
    const modelos = modelosBanco.filter(m =>
      nomesHistorico.some(n => n.toLowerCase() === m.nome.toLowerCase())
    );
  
    if (modelos.length === 0) {
      return await sendBotMessage(sender, "‚ö†Ô∏è Ainda n√£o te mostrei nenhum modelo pra comparar. Quer ver algumas op√ß√µes?");
    }
  
    const contexto = `
  Voc√™ √© Anna, especialista da Vertex Store.
  
  Siga exatamente as diretrizes abaixo para responder qualquer cliente:
  
  TOM DE VOZ:
  ${JSON.stringify(tomDeVozVertexData, null, 2)}
  
  OBJE√á√ïES COMUNS:
  ${JSON.stringify(obje√ß√µesVertex, null, 2).slice(0, 3000)}
  
  GATILHOS EMOCIONAIS:
  ${JSON.stringify(gatilhosEmocionaisVertex, null, 2)}

  TOM DE DESCONTOS ENTREGA E LOJA
  ${JSON.stringify(intencaoDataEntregaDesconto, null, 2)}
  `;
  
    const prompt = `
  ## OBJETIVO
  Guiar o cliente at√© escolher um smartphone da lista apresentada e fechar a venda,
  sempre valorizando experi√™ncia, suporte humanizado e diferencial da loja.
  utilize um tom de voz formal
  
  ## TOM_DE_VOZ (tomDeVozVertex)
  - Sauda√ß√£o acolhedora por√©m direta.
  - Use vocativo informal respeitoso (ex.: ‚ÄúPerfeito, Felipe!‚Äù).
  - Emojis: üíú obrigat√≥rio + 1 contextual; use üî• para descontos.
  - At√© 250 caracteres por bloco; quebre linhas por assunto.
  - Pontua√ß√£o dupla (‚Äú!!‚Äù, ‚Äú‚Ä¶‚Äù ) permitida.
  
  ## GATILHOS_EMOCIONAIS (gatilhosEmocionaisVertex)
  - Priorize Seguran√ßa ‚ûú Rapidez ‚ûú Transfer√™ncia de dados na hora.
  - Explore ‚ÄúGarantia emp√°tica‚Äù, ‚ÄúTelefone reserva‚Äù, ‚ÄúLoja f√≠sica confi√°vel‚Äù.
  - Conecte benef√≠cios √† vida di√°ria (produtividade, mem√≥rias, status).
  
  ## OBJE√á√ïES & COMPARATIVOS (obje√ß√µesVertex)
  - Se cliente comparar pre√ßo online ‚Üí explique valor agregado.
  - Descontos: s√≥ R$ 100 √† vista, ofere√ßa **ap√≥s** defender valor.
  - Parcelamento padr√£o 10√ó; ofere√ßa 12√ó **apenas se insistir** muito.
  - Use analogias para comparar servi√ßos (ex.: ‚Äúcomprar s√≥ pre√ßo √© como‚Ä¶‚Äù).
  
  ## REGRAS_DE_ESTILO
  - Nunca comece resposta com sauda√ß√£o completa; a conversa j√° est√° em andamento.
  - Seja conciso e humanizado; m√°ximo 3 blocos (‚Äúemo√ß√£o‚Äù, ‚Äúbenef√≠cio‚Äù, ‚Äúcall-to-action‚Äù).
  - Sempre feche perguntando algo que avance (ex.: ‚ÄúFecho em 10√ó pra voc√™?‚Äù).
  ###############################
  
  üìú Hist√≥rico da conversa:
  ${conversaCompleta}
  
  üì® √öltima mensagem do cliente:
  "${extras.msgContent}"
  
  üì± Modelos apresentados:
  ${modelos.map(m => `‚û°Ô∏è *${m.nome}*\n${m.descricao}\nüíµ Pre√ßo: R$ ${m.preco.toFixed(2)}`).join("\n")}
  
  üí∞ Pre√ßos:
  ${modelos.map(m => `‚Ä¢ ${m.nome}: R$ ${m.preco.toFixed(2)}`).join("\n")}
  
  Nome do usu√°rio:
  ${nome}
  `;
  
    // Chamada √† IA com function calling
    const respostaIA = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: contexto },
        { role: "user", content: prompt }
      ],
      functions,
      function_call: "auto",
      temperature: 1,
      max_tokens: 300
    });
  
    const escolha = respostaIA.choices[0]?.message;
  
    // üîÅ Se a IA decidir por uma function_call
    if (escolha?.function_call) {
      const { name, arguments: argsStr } = escolha.function_call;
      const args = argsStr ? JSON.parse(argsStr) : {};
      const modeloEscolhido = modelos[0]; // pode ser o √∫ltimo demonstrado tamb√©m
  
      if (handlers[name]) {
        return await handlers[name](sender, args, { ...extras, modeloEscolhido });
      }
    }
  
    // üîÑ Caso apenas queira continuar a conversa
    const respostaFinal = escolha?.content?.trim();
    if (!respostaFinal) {
      return await sendBotMessage(sender, "üìå Estou verificando... Pode repetir a d√∫vida de forma diferente?");
    }
  
    return await sendBotMessage(sender, respostaFinal);
  }
}

const functions = [
  {
    name: "fecharVenda",
    description: "Chama o agente de fechamento ap√≥s o resumo e o video terem sido enviados e depois que o cliente quiser comprar ou agendar.",
    parameters: {
      type: "object",
      properties: {
        confirmacao: { type: "string", description: "Inten√ß√£o de compra/agendamento" },
      },
      required: ["confirmacao"],
    },
  },
  {
    name: "mostrarResumoModelo",
    description: "Mostra o v√≠deo e o resumo formatado de um modelo espec√≠fico reconhecido.",
    parameters: {
      type: "object",
      properties: {
        nomeModelo: { type: "string", description: "Nome exato do modelo reconhecido" }
      },
      required: ["nomeModelo"],
    },
  },
  {
    name: "responderDuvida",
    description: "Responde a uma d√∫vida espec√≠fica do cliente sobre um ou mais modelos sugeridos anteriormente.",
    parameters: {
      type: "object",
      properties: {
        resposta: {
          type: "string",
          description: "Texto da resposta explicando diferen√ßas, vantagens ou informa√ß√µes adicionais."
        }
      },
      required: ["resposta"]
    }
  },
];

 
module.exports = {
  agenteDeDemonstracaoDetalhadaBoleto
  
};

