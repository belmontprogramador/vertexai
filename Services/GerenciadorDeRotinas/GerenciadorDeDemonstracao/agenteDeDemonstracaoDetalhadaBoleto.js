// üîÑ Agente GPT completo com l√≥gica igual a identificarModeloPorNome
const { sendBotMessage } = require("../../messageSender");
const {
  setUserStage,
  appendToConversation,
  getConversation,
  getNomeUsuario,
  getUserStage,
} = require("../../redisService");
const { getAllCelulareBoleto } = require("../../dbService");
const { rotinaDeAgendamento } = require("../../GerenciadorDeRotinas/GerenciadorDeAgendamento/rotinaDeAgendamento");
const OpenAI = require("openai");
require("dotenv").config();
const { obje√ß√µesVertexBoleto } = require("../../../Services/utils/objecoesBoleto");
const { informacoesPayjoy } = require("../../../Services/utils/informacoesPayjoy");
const { gatilhosEmocionaisVertex } = require('../../../Services/utils/gatilhosEmocionais'); 
const { intencaoDataEntregaDesconto } = require('../../../Services/utils/intencaoDataEntregaDesconto');
const { tomDeVozVertexData } = require("../../../Services/utils/tomDeVozVertexData");
const { extrairTextoDoQuotedMessage } = require("../../utils/extrairTextoDoQuotedMessage");

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const obterModelosDoBling = async () => {
  const celulares = await getAllCelulareBoleto();

  const termosIgnorados = [
    "BLACK", "WHITE", "BLUE", "GREEN", "GOLD", "PURPLE", "SILVER", "CORAL",
    "MIDNIGHT", "OCEAN", "TEAL", "AZUL", "VERDE", "LAVENDER", "VOYAGE",
    "MARBLE", "STORM", "LIGHTNING", "SPARKLE", "DARK", "LIME", "STAR", "STARRY",
    "OC√âANO", "ROM", "RAM"
  ];

  const normalizeNome = (nome) =>
    nome
      .replace(/^smartphone\s*/i, "")
      .replace(/[^\w\s]/gi, "")
      .trim()
      .split(/\s+/)
      .filter((p) => !termosIgnorados.includes(p.toUpperCase()))
      .join(" ")
      .toLowerCase()
      .trim();

  const mapaUnico = new Map();

  for (const c of celulares) {
    const chave = normalizeNome(c.nome);
    if (!mapaUnico.has(chave)) {
      mapaUnico.set(chave, {
        nome: c.nome,
        preco: c.preco,
        descricaoCurta: c.descricao, // ‚úÖ Corrigido aqui!
        imagemURL: c.imageURL,
        precoParcelado: c.precoParcelado,
        fraseImpacto: c.fraseImpacto,
        subTitulo: c.subTitulo,
        videoURL: c.videoURL,
      });
    }
  }

  return Array.from(mapaUnico.values());
};

const calcularSimilaridadePorEmbeddings = async (entrada, modelos) => {
  const entradaEmbedding = await openai.embeddings.create({ model: "text-embedding-3-small", input: entrada });
  const modelosEmbedding = await openai.embeddings.create({ model: "text-embedding-3-small", input: modelos.map(m => m.nome) });
  const vetorEntrada = entradaEmbedding.data[0].embedding;
  return modelosEmbedding.data.map((item, i) => {
    const m = modelos[i];
    const score = vetorEntrada.reduce((acc, val, idx) => acc + val * item.embedding[idx], 0);
    return { ...m, score };
  }).sort((a, b) => b.score - a.score);
}; 

const agenteDeDemonstracaoDetalhadaBoleto = async ({ sender, msgContent, pushName }) => {
  try {
    await setUserStage(sender, "agente_de_demonstracao_pos_decisao_por_boleto")
    const nome = await getNomeUsuario(sender);
    const textoQuoted = extrairTextoDoQuotedMessage(msgContent);

    let entrada = typeof msgContent === "string" ? msgContent : msgContent?.termosRelacionados || "";
    if ((!entrada || entrada.toLowerCase().includes("esse")) && textoQuoted) {
      entrada = textoQuoted;
    }

    entrada = entrada.trim().replace(/^again\s*/i, "") || "o cliente marcou uma mensagem mas n√£o escreveu nada";
    await appendToConversation(sender, entrada);
    console.log("üìú Hist√≥rico completo (raw):", conversa);

    const conversa = await getConversation(sender);
    const conversaCompleta = conversa.slice(-10).join(" | ");
    const modelosRecentes = conversa
      .filter(m => m.startsWith("modelo_sugerido_json:") || m.startsWith("modelo_sugerido:"))
      .map(m => {
        try {
          return m.startsWith("modelo_sugerido_json:")
            ? JSON.parse(m.replace("modelo_sugerido_json: ", ""))
            : { nome: m.replace("modelo_sugerido: ", ""), descricaoCurta: "(descri√ß√£o n√£o dispon√≠vel)", preco: "pre√ßo n√£o informado" };
        } catch {
          return null;
        }
      })
      .filter(Boolean);
      console.log("üì¶ Modelos recentes identificados no hist√≥rico:", modelosRecentes);

    const listaParaPrompt = await obterModelosDoBling();
    const similaridades = await calcularSimilaridadePorEmbeddings(entrada, listaParaPrompt);
    console.log("üß† Similaridades calculadas:", similaridades.map(s => ({ nome: s.nome, score: s.score })));
    const modeloEscolhido = similaridades?.[0];

    const deliberarPossibilidades = async () => {
      const prompt = `
Cliente enviou: "${entrada}"
MODELOS MOSTRADOS:
${modelosRecentes.map(m => `- ${m.nome}`).join("\n") || "(nenhum modelo mostrado ainda)"}

üí° Quais s√£o as 3 possibilidades mais prov√°veis que o cliente quer com essa mensagem?
1. Se ‚Äî e SOMENTE SE ‚Äî o cliente disser explicitamente frases como "fechou", "quero esse", "vamos fechar", "√© esse mesmo", "bora", "fechado", ou mencionar uma data exata de fechamento como "vou hoje", "passo a√≠ amanh√£", "m√™s que vem", ent√£o ele est√° confirmando um dos modelos sugeridos. Escolha "fecharVenda".

2. Se o cliente fizer QUALQUER pergunta mesmo sem usar ponto de ? ‚Äî mesmo curta ‚Äî como "√© bom?", "e esse?", "a c√¢mera √© boa?", "qual o pre√ßo?", ou mostrar d√∫vida sobre qualquer aspecto, isso deve ser interpretado como que ele ainda est√° indeciso e precisa de mais informa√ß√µes. Escolha "responderDuvida".

3. Se ele mencionar um modelo, √© "mostrarResumoModeloBoleto".

Retorne em formato JSON:
{
  possibilidades: [
    { acao: "", motivo: "" }
  ]
}`;
      const resp = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [{ role: "user", content: prompt }],
        temperature: 0.9
      });

      const raw = resp.choices?.[0]?.message?.content || "";
      const jsonMatch = raw.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        console.error("‚ùå Nenhum JSON v√°lido encontrado na resposta:", raw);
        return null;
      }

      return JSON.parse(jsonMatch[0]);
    };

    const avaliarMelhorCaminho = (possibilidades, extras) => {
      const { msgContent = "", quotedMessage = "" } = extras || {};
      const texto = `${msgContent} ${quotedMessage}`.toLowerCase();
      if (!possibilidades?.possibilidades || possibilidades.possibilidades.length === 0) {
        return "responderDuvida";
      }
      return possibilidades.possibilidades[0].acao;
    };

    const resultadoTOA = await deliberarPossibilidades();
    const acaoEscolhida = avaliarMelhorCaminho(resultadoTOA, { msgContent, quotedMessage: textoQuoted });

    console.log("üéØ Resultado TOA:", JSON.stringify(resultadoTOA, null, 2));

    if (handlers[acaoEscolhida]) {
      return await handlers[acaoEscolhida](sender, {}, {
        modeloEscolhido,
        msgContent: entrada,
        pushName,
        conversaCompleta
      });
    }

    return await sendBotMessage(sender, "‚ö†Ô∏è N√£o entendi sua escolha. Pode repetir?");
  } catch (error) {
    console.error("‚ùå Erro no agenteDeDemonstracaoDetalhadaBoleto:", error);
    return await sendBotMessage(sender, "‚ö†Ô∏è Ocorreu um erro. Pode tentar de novo?");
  }
};


const handlers = {
  fecharVenda: async (sender, _args, extras) => {
    const { modeloEscolhido, pushName, msgContent } = extras;
    return await rotinaDeAgendamento({ sender, msgContent, pushName });
  },
  mostrarResumoModeloBoleto: async (sender, args, extras) => {
    await setUserStage(sender, "agente_de_demonstracao_pos_decisao_por_boleto")
      let modelo = extras?.modeloEscolhido;
      const nome = await getNomeUsuario(sender);
    
      const normalize = (str) =>
        str.toLowerCase()
          .normalize("NFD")
          .replace(/[\u0300-\u036f]/g, "")
          .replace(/[^\w\s]/gi, "")
          .replace(/\s+/g, " ")
          .trim();
    
      if (!modelo && args?.nomeModelo) {
        const lista = await obterModelosDoBling();
        modelo = lista.find(m => normalize(m.nome) === normalize(args.nomeModelo));
      }
    
      if (!modelo) {
        await sendBotMessage(sender, `Opa ${nome} acho que a gente conversou sobre mais de um modelo e fiquei na duvida qual voc√™ escolheu`)
        return await sendBotMessage(sender, "Pode me dizer qual o modelo exato que voc√™ escolheu?" );
      }
    
      // Gera√ß√£o do resumo via GPT
      const prompt = [
        {
          role: "system",
          content: `Voc√™ √© um vendedor persuasivo e direto. 
          Seja direto, com no m√°ximo 3 frases curtas. Priorize clareza e impacto, n√£o ultrapasse 250 caracteres no total.
  
          ***Fa√ßa o mais resumido possivel para usar o token e n√£o faltar mensagem***
          Use uma linguagem formal mas descontraida.
          pule semre uma linha entre o resumo e a mensagem do tom de voz
          de preferencia ao pre√ßo parcelado
          Nome do cliente ${nome}
          Ao final sempre fa√ßa perguntas utilizando esse documento como base:
          TOM DE VOZ:
          ${JSON.stringify(tomDeVozVertexData, null, 2)}
          
          `
        },
        {
          role: "user",
          content: `Modelo: ${modelo.nome}\nFrase de impacto: ${modelo.fraseImpacto}\nDescri√ß√£o curta: ${modelo.descricaoCurta}`
        }
      ];
    
      let resumo = "";
      try {
        const resposta = await openai.chat.completions.create({
          model: "gpt-4",
          messages: prompt,
          temperature: 0.99,
          max_tokens: 150
        });
    
        resumo = resposta.choices?.[0]?.message?.content?.trim() || "";
      } catch (err) {
        console.error("Erro ao gerar resumo com GPT:", err);
        resumo = `üì± *${modelo.nome}*\n${modelo.fraseImpacto}\nüí∞ R$ ${modelo.preco.toFixed(2)}\n\nEm breve te explico mais!`;
      }  
      
   // Salva no hist√≥rico
   await appendToConversation(sender, `modelo_sugerido_json: ${JSON.stringify(modelo)}`);
  
      // Envia o v√≠deo com o mesmo resumo como legenda
      if (modelo.videoURL) {
        await sendBotMessage(sender, {
          videoUrl: modelo.videoURL,
          caption: resumo
        });
      }
     
    },
  responderDuvida: async (sender, _args, extras) => {
    await setUserStage(sender, "agente_de_demonstra√ß√£o_detalhada_boleto");
    await sendBotMessage(sender,"reposnder duvida")
  
    const historico = await getConversation(sender);
    const conversaCompleta = historico.map(f => f.replace(/^again\s*/i, "").trim()).slice(-10).join(" | ");
    const modelosBanco = await getAllCelulareBoleto();
    const nome = await getNomeUsuario(sender);
  
    const nomesHistorico = historico
      .filter(m => m.startsWith("modelo_sugerido_json:") || m.startsWith("modelo_sugerido:"))
      .map(m => {
        if (m.startsWith("modelo_sugerido_json:")) {
          try {
            const obj = JSON.parse(m.replace("modelo_sugerido_json:", ""));
            return obj.nome;
          } catch {
            return null;
          }
        }
        return m.replace("modelo_sugerido: ", "").trim();
      })
      .filter(Boolean);
  
    const modelos = modelosBanco.filter(m =>
      nomesHistorico.some(n => n.toLowerCase() === m.nome.toLowerCase())
    );
  
    if (modelos.length === 0) {
      return await sendBotMessage(sender, "‚ö†Ô∏è Ainda n√£o te mostrei nenhum modelo pra comparar. Quer ver algumas op√ß√µes?");
    }
  
    const contexto = `
  Voc√™ √© Anna, especialista da Vertex Store.
  
  Siga exatamente as diretrizes abaixo para responder qualquer cliente:
  
  TOM DE VOZ:
  ${JSON.stringify(tomDeVozVertexData, null, 2)}
  
  OBJE√á√ïES COMUNS:
  ${JSON.stringify(obje√ß√µesVertexBoleto, null, 2).slice(0, 3000)}
  
  GATILHOS EMOCIONAIS:
  ${JSON.stringify(gatilhosEmocionaisVertex, null, 2)}

     OBJE√á√ïES SOBRE PAYJOY:
    ${JSON.stringify(informacoesPayjoy).slice(0, 3500)}

  TOM DE DESCONTOS ENTREGA E LOJA
  ${JSON.stringify(intencaoDataEntregaDesconto, null, 2)}
  `;
  
    const prompt = `
  ## OBJETIVO
  Guiar o cliente at√© escolher um smartphone da lista apresentada e fechar a venda,
  sempre valorizando experi√™ncia, suporte humanizado e diferencial da loja.
  utilize um tom de voz formal
  Sua miss√£o √© extrair do cliente uma data para fazer uma visita a loja
  
  ## TOM_DE_VOZ (tomDeVozVertex)
  - Sauda√ß√£o acolhedora por√©m direta.
  - Use vocativo informal respeitoso (ex.: ‚ÄúPerfeito, Felipe!‚Äù).
  - Emojis: üíú obrigat√≥rio + 1 contextual; use üî• para descontos.
  - At√© 250 caracteres por bloco; quebre linhas por assunto.
  - Pontua√ß√£o dupla (‚Äú!!‚Äù, ‚Äú‚Ä¶‚Äù ) permitida.
  
  ## GATILHOS_EMOCIONAIS (gatilhosEmocionaisVertex)
  - Priorize Seguran√ßa ‚ûú Rapidez ‚ûú Transfer√™ncia de dados na hora.
  - Explore ‚ÄúGarantia emp√°tica‚Äù, ‚ÄúTelefone reserva‚Äù, ‚ÄúLoja f√≠sica confi√°vel‚Äù.
  - Conecte benef√≠cios √† vida di√°ria (produtividade, mem√≥rias, status).
  
  ## OBJE√á√ïES & COMPARATIVOS (obje√ß√µesVertex)
  - Se cliente comparar pre√ßo online ‚Üí explique valor agregado.
  - Descontos: n√£o oferecemos desconto no boleto.
  - Parcelamento padr√£o 18√ó.
  - Use analogias para comparar servi√ßos (ex.: ‚Äúcomprar s√≥ pre√ßo √© como‚Ä¶‚Äù).
  
  ## REGRAS_DE_ESTILO
  - Nunca comece resposta com sauda√ß√£o completa; a conversa j√° est√° em andamento.
  - Seja conciso e humanizado; m√°ximo 3 blocos (‚Äúemo√ß√£o‚Äù, ‚Äúbenef√≠cio‚Äù, ‚Äúcall-to-action‚Äù).
  - Sempre feche perguntando algo que avance (ex.: ‚Äúvamos agendar sua visita‚Äù, "quando voce pode vir a loja").
  ###############################
  
  üìú Hist√≥rico da conversa:
  ${conversaCompleta}
  
  üì® √öltima mensagem do cliente:
  "${extras.msgContent}"
  
  üì± Modelos apresentados:
  ${modelos.map(m => `‚û°Ô∏è *${m.nome}*\n${m.descricao}\nüíµ Pre√ßo: R$ ${m.preco.toFixed(2)}`).join("\n")}
  
  üí∞ Pre√ßos:
  ${modelos.map(m => `‚Ä¢ ${m.nome}: R$ ${m.preco.toFixed(2)}`).join("\n")}
  
  Nome do usu√°rio:
  ${nome}
  `;
  
    // Chamada √† IA com function calling
    const respostaIA = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: contexto },
        { role: "user", content: prompt }
      ],
      temperature: 1,
      max_tokens: 300
    });
    
    const escolha = respostaIA.choices[0]?.message;
    
    // Caso a IA apenas responda diretamente
    const respostaFinal = escolha?.content?.trim();
    if (!respostaFinal) {
      return await sendBotMessage(sender, "üìå Estou verificando... Pode repetir a d√∫vida de forma diferente?");
    }
    
    return await sendBotMessage(sender, respostaFinal);
   
}
}

 
module.exports = {
  agenteDeDemonstracaoDetalhadaBoleto,
  handlers
  
};

