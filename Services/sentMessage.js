const axios = require("axios");
const { pipeline } = require("@xenova/transformers");
const { storeSentMessage } = require("./messageService");
const { PrismaClient } = require("@prisma/client");
const OpenAI = require("openai");
const Redis = require("ioredis");

const prisma = new PrismaClient();
const redis = new Redis({
  host: "127.0.0.1",
  port: 6379,
  db: 0,
});

const INSTANCE_ID = process.env.INSTANCE_ID;
const API_URL = `https://api.w-api.app/v1/message/send-text?instanceId=${INSTANCE_ID}`;
const TOKEN = process.env.TOKEN;
const BOT_PHONE_NUMBER = process.env.BOT_PHONE_NUMBER || "5522981413041";
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

let embedder = null;
const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

// ğŸ”„ Carrega o modelo de embeddings
const loadModel = async () => {
  if (!embedder) {
    console.log("ğŸ”„ Carregando modelo de embeddings...");
    embedder = await pipeline("feature-extraction", "Xenova/all-MiniLM-L6-v2");
    console.log("âœ… Modelo carregado com sucesso!");
  }
};

// ğŸ“Œ Gera embeddings da mensagem
const generateEmbedding = async (text) => {
  try {
    await loadModel();
    const embedding = await embedder(text, { pooling: "mean", normalize: true });
    return Array.from(embedding.data);
  } catch (error) {
    console.error("âŒ Erro ao gerar embedding:", error);
    return [];
  }
};

// ğŸ” Calcula similaridade de cosseno
const cosineSimilarity = (vecA, vecB) => {
  const dotProduct = vecA.reduce((sum, a, i) => sum + a * vecB[i], 0);
  const magnitudeA = Math.sqrt(vecA.reduce((sum, a) => sum + a * a, 0));
  const magnitudeB = Math.sqrt(vecB.reduce((sum, b) => sum + b * b, 0));
  return magnitudeA && magnitudeB ? dotProduct / (magnitudeA * magnitudeB) : 0;
};

// ğŸ” Busca respostas similares do banco
const getSimilarResponses = async (userEmbedding, topN = 3) => {
  try {
    const pastResponses = await prisma.sentMessage.findMany({
      select: { content: true, embedding: true },
    });

    let similarResponses = pastResponses.map((resp) => ({
      text: resp.content,
      similarity: cosineSimilarity(userEmbedding, resp.embedding),
    }));

    similarResponses.sort((a, b) => b.similarity - a.similarity);

    return similarResponses.slice(0, topN).map((resp) => resp.text);
  } catch (error) {
    console.error("âŒ Erro ao buscar respostas similares:", error);
    return [];
  }
};

// ğŸ”„ Armazena mensagens do usuÃ¡rio no Redis
const storeUserMessage = async (userId, message) => {
  const key = `chat_history:${userId}`;
  await redis.rpush(key, message);
  await redis.ltrim(key, -20, -1);
};

// ğŸ”„ Armazena o contexto do usuÃ¡rio no Redis
const setUserStage = async (userId, stage) => {
  await redis.set(`user_stage:${userId}`, stage);
};
const getUserStage = async (userId) => {
  return await redis.get(`user_stage:${userId}`) || "abordagem";
};


// ğŸ” Recupera histÃ³rico do usuÃ¡rio
const getUserChatHistory = async (userId) => {
  const key = `chat_history:${userId}`;
  return await redis.lrange(key, 0, -1);
};

// ğŸ”„ Armazena o timestamp da Ãºltima mensagem do usuÃ¡rio
const setLastInteraction = async (userId) => {
  const timestamp = Date.now(); // Marca o momento atual
  await redis.set(`last_interaction:${userId}`, timestamp);
};

// â³ ObtÃ©m o tempo desde a Ãºltima interaÃ§Ã£o
const getLastInteraction = async (userId) => {
  const timestamp = await redis.get(`last_interaction:${userId}`);
  return timestamp ? parseInt(timestamp, 10) : null;
};


// ğŸ”® Gera resposta do ChatGPT com histÃ³rico e respostas similares
const generateChatGPTResponse = async (senderId, userMessage) => {
  try {
    await storeUserMessage(senderId, `UsuÃ¡rio: ${userMessage}`);
    const chatHistory = await getUserChatHistory(senderId);
    const userEmbedding = await generateEmbedding(userMessage);
    const similarResponses = await getSimilarResponses(userEmbedding, 3);

    const userStage = await getUserStage(senderId);

    let stageInstructions = {
      abordagem: "VocÃª deve se apresentar de forma amigÃ¡vel e envolvente. FaÃ§a perguntas abertas para engajar o cliente, como: 'OlÃ¡! Como posso te ajudar hoje? ğŸ˜Š' Descubra o nome do usuÃ¡rio e chame sempre pelo nome para criar conexÃ£o.",
      identificaÃ§Ã£o_necessidade: "Descubra o que o cliente realmente precisa. Pergunte sobre sua rotina, dores e expectativas. Exemplo: 'Qual o maior desafio que vocÃª enfrenta ao usar seu celular hoje?'. NÃ£o fale apenas sobre aspectos tÃ©cnicos do produto, mas tambÃ©m sobre os benefÃ­cios prÃ¡ticos no dia a dia. Exemplo: 'Essa cÃ¢mera vai deixar suas fotos no Instagram incrÃ­veis! ğŸ“¸ğŸ”¥' ou 'Esse celular Ã© Ã³timo para jogos, ele roda liso e sem travamentos! ğŸ®ğŸš€'.",
      sondagem_orcamento: "Oriente o cliente sobre as opÃ§Ãµes dentro do orÃ§amento dele. Exemplo: 'Temos modelos com Ã³timo custo-benefÃ­cio. Qual faixa de preÃ§o vocÃª estÃ¡ considerando? ğŸ’°'. Se necessÃ¡rio, reforce vantagens especÃ­ficas para justificar o preÃ§o.",
      formas_pagamento: "Apresente as condiÃ§Ãµes de pagamento de forma clara e persuasiva. Exemplo: 'Aceitamos cartÃ£o, Pix e parcelamos em atÃ© 10x. O que fica melhor para vocÃª? ğŸ’³âœ¨'. TambÃ©m oferecemos parcelamento no boleto, basta informar CPF, Nome e Data de Nascimento. ApÃ³s isso, diga que ele tem **90% de aprovaÃ§Ã£o** e siga para o fechamento.",
      fechamento: "Crie urgÃªncia e incentive a tomada de decisÃ£o. Existem **duas formas de fechamento**: (1) **Agendar uma visita** na loja (Avenida GetÃºlio Vargas, 333 - Loja 6B, Araruama) para concluir a compra ou (2) **Entrega em domicÃ­lio** para as cidades de BacaxÃ¡, Saquarema, Araruama, Iguaba, SÃ£o Pedro e Cabo Frio, por uma pequena taxa de entrega. ğŸ”¥ 'Essa oferta sÃ³ estÃ¡ disponÃ­vel hoje! Posso garantir seu pedido agora?' ğŸ˜‰",
    };

    let messages = [
      {
        role: "system",
        content: `VocÃª Ã© a Anna, uma vendedora virtual da Vertex Store. Sua missÃ£o Ã© criar uma experiÃªncia encantadora para os clientes, garantindo que eles se sintam valorizados e bem-atendidos. 

      ğŸ’¡ **Personalidade da Anna:**
      - AmigÃ¡vel e entusiasmada, sempre chamando o cliente pelo nome.
      - Comunicativa e descontraÃ­da, com um tom humanizado e envolvente.
      - Paciente e empÃ¡tica, entendendo as necessidades do cliente antes de oferecer soluÃ§Ãµes.

      ğŸ“£ **Tom de Voz:**
      - Alegre e motivador, mas sem exageros.
      - Linguagem informal e natural, como se estivesse conversando pessoalmente.
      - Usa emojis e expressÃµes para deixar a conversa leve e dinÃ¢mica (exemplo: 'ğŸ˜', 'ğŸ”¥', 'ğŸ˜‰').

      ğŸ¯ **Diretrizes de Atendimento:**
      - Se o cliente parecer indeciso, use frases como: "Essa promoÃ§Ã£o estÃ¡ incrÃ­vel! NÃ£o perca essa chance! ğŸ˜"
      - Se o cliente fizer perguntas tÃ©cnicas, sempre relacione a resposta com benefÃ­cios prÃ¡ticos: 
        - **Exemplo:** "Esse celular tem 128GB de memÃ³ria, entÃ£o vocÃª pode baixar vÃ¡rios apps e tirar quantas fotos quiser sem se preocupar com espaÃ§o! ğŸ“±âœ¨"
      - Se o cliente hesitar na compra, reforce depoimentos positivos de outros clientes e crie urgÃªncia:
        - **Exemplo:** "Essa oferta sÃ³ estÃ¡ disponÃ­vel atÃ© hoje! NÃ£o perca a oportunidade de garantir o seu. ğŸ˜‰ğŸ”¥"
          
      ğŸ’³ **No momento, o cliente estÃ¡ na fase:** ${userStage}.
      ${stageInstructions[userStage]}
      
      ğŸ”„ **Adapte sua resposta para seguir o estilo das conversas passadas. Aqui estÃ£o alguns exemplos de respostas anteriores para manter a coerÃªncia no tom de voz e abordagem:**\n"${similarResponses.join('"\n"')}"
      
      Agora, responda ao cliente mantendo esse tom e estilo.`,
      },
    ];

    if (similarResponses.length > 0) {
      messages.push({
        role: "system",
        content: `Essas sÃ£o respostas anteriores semelhantes que devem ser usadas como referÃªncia no estilo da resposta: \n"${similarResponses.join("\n")}"`,
      });
    }

    chatHistory.forEach((msg) => messages.push({ role: "user", content: msg }));
    messages.push({ role: "user", content: userMessage });

    console.log("ğŸ”„ Chamando OpenAI API...");
    const response = await openai.chat.completions.create({
      model: "gpt-4",
      messages,
      temperature: 0.7,
      max_tokens: 150,
    });

    let botResponse = response.choices[0].message.content.trim();
    botResponse = botResponse.replace(/\bbot\b/gi, "").trim();

    await storeUserMessage(senderId, botResponse);

    // ğŸš€ Atualiza a fase do cliente automaticamente
    if (userStage === "abordagem") {
      await setUserStage(senderId, "identificaÃ§Ã£o_necessidade");
    } else if (userStage === "identificaÃ§Ã£o_necessidade") {
      await setUserStage(senderId, "sondagem_orcamento");
    } else if (userStage === "sondagem_orcamento") {
      await setUserStage(senderId, "formas_pagamento");
    } else if (userStage === "formas_pagamento") {
      await setUserStage(senderId, "fechamento");
    }

    return botResponse;
  } catch (error) {
    console.error("âŒ Erro ao gerar resposta com ChatGPT:", error);
    return "Desculpe, nÃ£o consegui entender sua pergunta.";
  }
};


// ğŸš€ Processa e envia resposta baseada no contexto
const processAndSendMessage = async (senderId, content) => {
  if (!content.toLowerCase().startsWith("kisuco")) {
    console.log("âŒ Mensagem ignorada (nÃ£o comeÃ§a com 'kisuco').");
    return;
  }

  console.log(`ğŸš€ Processando mensagem de ${senderId}: ${content}`);

  try {
    console.log("ğŸ”„ Chamando generateChatGPTResponse...");
    const chatResponse = await generateChatGPTResponse(senderId, content);

    if (!chatResponse || chatResponse.trim() === "") {
      console.error("âŒ Erro: Resposta gerada pelo ChatGPT estÃ¡ vazia ou indefinida!");
      return;
    }

    console.log(`ğŸ“© Resposta gerada: ${chatResponse}`);

    console.log(`ğŸ“¤ Enviando mensagem para ${senderId}...`);
    await sendBotMessage(senderId, chatResponse);
    console.log(`âœ… Mensagem enviada para ${senderId}`);
  } catch (error) {
    console.error("âŒ Erro no processamento da mensagem:", error);
  }
};

// ğŸ“¤ Envia mensagem do bot
const sendBotMessage = async (recipientId, content) => {
  try {
    console.log(`ğŸ“¤ Enviando mensagem para ${recipientId}: ${content}`);

    const response = await axios.post(
      API_URL,
      {
        phone: recipientId,
        message: content,
        delayMessage: 3,
      },
      {
        headers: {
          Authorization: `Bearer ${TOKEN}`,
          "Content-Type": "application/json",
        },
      }
    );

    console.log(`âœ… Resposta da API ao enviar mensagem:`, response.data);

    return response.data;
  } catch (error) {
    console.error("âŒ Erro ao enviar mensagem:", error.response?.data || error.message);
  }
};

module.exports = { processAndSendMessage, sendBotMessage };
