const OpenAI = require("openai");
const { 
  storeUserMessage, 
  getUserStage, 
  getUserChatHistory 
} = require("./redisService");
const { 
    validateStageProgression, // âœ… Use esta funÃ§Ã£o em vez de `correctUserStage`
    getStageFromUserInput 
  } = require("./salesStages");
  

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const CONVERSION_PROMPT = `
VocÃª Ã© Anna, uma vendedora especializada em vendas e atendimento ao cliente da Vertex Store.
Sua funÃ§Ã£o Ã© transformar um contexto inicial em uma rotina programÃ¡tica de atendimento para um processo de vendas.

**InstruÃ§Ãµes:**
1ï¸âƒ£ **Analise o contexto recebido** e determine em qual estÃ¡gio do processo de vendas o cliente estÃ¡.
2ï¸âƒ£ **Se o cliente pulou etapas, ajuste-o para o estÃ¡gio correto** antes de avanÃ§ar.
3ï¸âƒ£ **Se o cliente voltou a uma dÃºvida anterior, retroceda o estÃ¡gio conforme necessÃ¡rio**.
4ï¸âƒ£ **Divida as etapas em aÃ§Ãµes numeradas e subaÃ§Ãµes identificadas por letras**.
5ï¸âƒ£ **Use a lÃ³gica 'IF... THEN'** para guiar a conversa de maneira estruturada.
6ï¸âƒ£ **Sempre peÃ§a informaÃ§Ãµes necessÃ¡rias ao usuÃ¡rio** antes de avanÃ§ar para a prÃ³xima etapa.
7ï¸âƒ£ **Sempre armazene as interaÃ§Ãµes do usuÃ¡rio no Redis** para manter um histÃ³rico.
8ï¸âƒ£ **Atualize o estÃ¡gio do usuÃ¡rio no Redis ao final de cada etapa relevante**.
9ï¸âƒ£ **A Ãºltima aÃ§Ã£o sempre deve ser perguntar se hÃ¡ algo mais com que pode ajudar**.
10ï¸âƒ£ **Se nÃ£o houver contexto suficiente, peÃ§a mais informaÃ§Ãµes ao usuÃ¡rio**.

Agora gere a rotina com base no seguinte contexto:
`;

/**
 * ğŸ”„ Gera a rotina de atendimento com base no contexto e executa aÃ§Ãµes do Redis
 * @param {string} userId - ID do usuÃ¡rio
 * @param {string} userInput - Mensagem do usuÃ¡rio
 * @returns {Promise<string>} - Retorna a resposta da rotina gerada
 */

const generateRoutine = async (userId, userInput) => {
    try {
        console.log(`ğŸ” Gerando rotina para usuÃ¡rio ${userId} com mensagem: ${userInput}`);

        // ğŸ“Œ ObtÃ©m o estÃ¡gio do usuÃ¡rio no Redis
        let userStage = await getUserStage(userId);
        console.log(`ğŸ“Œ O usuÃ¡rio ${userId} estÃ¡ no estÃ¡gio: ${userStage}`);

        // ğŸ”„ Determina o estÃ¡gio correto com base na entrada do usuÃ¡rio
        const detectedStage = getStageFromUserInput(userInput, userStage);

       // ğŸ”„ Ajusta o estÃ¡gio se o usuÃ¡rio tiver avanÃ§ado ou retrocedido de forma errada
if (detectedStage !== userStage) {
    userStage = await validateStageProgression(userId, detectedStage, userStage); // âœ… Corrigido
}


        const chatHistory = await getUserChatHistory(userId);
        
        const messages = [
            {
                role: "assistant",
                content: `${CONVERSION_PROMPT}\nUsuÃ¡rio estÃ¡ no estÃ¡gio: ${userStage || "abordagem"}.\nHistÃ³rico de mensagens: ${chatHistory?.join(", ") || "Sem histÃ³rico"}.\nContexto: ${userInput}`
            }
        ];

        console.log("ğŸ“¡ Enviando requisiÃ§Ã£o ao OpenAI...");
        const response = await openai.chat.completions.create({
            model: "gpt-4-1106-preview", // ğŸ”„ Agora usando gpt-4-1106-preview
            messages,
            max_tokens: 3000,
        });

        console.log("âœ… Resposta bruta da OpenAI recebida.");

        if (!response.choices || response.choices.length === 0 || !response.choices[0].message) {
            throw new Error("âŒ Resposta vazia da OpenAI.");
        }

        const routine = response.choices[0].message.content.trim();
        console.log("ğŸ“œ ConteÃºdo da rotina gerada:", JSON.stringify(routine, null, 2));

        // ğŸ”„ Armazena a rotina no histÃ³rico do Redis
        await storeUserMessage(userId, `Anna (Rotina): ${routine}`);

        // âœ… Agora gera a resposta com base na rotina
        console.log("ğŸ“¡ Gerando resposta baseada na rotina...");
        const responseMessages = [
            {
                role: "assistant",
                content: `Com base na rotina abaixo, gere uma resposta clara e direta para o usuÃ¡rio:\n\n${routine}`
            }
        ];

        const responseAI = await openai.chat.completions.create({
            model: "gpt-4-1106-preview", // ğŸ”„ Agora usando gpt-4-1106-preview
            messages: responseMessages,
            max_tokens: 1000,
        });

        if (!responseAI.choices || responseAI.choices.length === 0 || !responseAI.choices[0].message) {
            throw new Error("âŒ Falha ao gerar a resposta final.");
        }

        const finalResponse = responseAI.choices[0].message.content.trim();
        console.log("ğŸ’¬ Resposta gerada para o usuÃ¡rio:", finalResponse);

        // ğŸ”„ Armazena a resposta gerada no histÃ³rico do Redis
        await storeUserMessage(userId, `Anna: ${finalResponse}`);

        return { routine, response: finalResponse };
    } catch (error) {
        console.error(`âŒ Erro ao gerar rotina e resposta: ${error.message}`);
        return { routine: "Erro ao gerar a rotina de atendimento.", response: "Erro ao gerar a resposta ao usuÃ¡rio." };
    }
};

module.exports = { generateRoutine };