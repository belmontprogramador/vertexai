const OpenAI = require("openai");
const { 
  storeUserMessage, 
  setUserStage,
  getUserStage, 
  getUserChatHistory,
  getLastInteraction,
  setLastInteraction,
} = require("./redisService");
const redis = require("./redisService").redis;

const { 
  validateStageProgression,
  getStageFromUserInput,
  STAGE_RULES
} = require("./salesStages");

const CHECK_TIME_LIMIT = 1 * 60 * 1000; // 5 minutos em milissegundos
const RESET_STAGE = "sondagem_de_orcamento"; // EstÃ¡gio inicial ao reiniciar

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// ğŸš€ DefiniÃ§Ã£o das perguntas da sondagem
const SURVEY_QUESTIONS = [
    "Qual o produto que vocÃª procura?",
    "Qual a necessidade e utilidade que vocÃª quer com o produto?",
    "Qual o valor que estÃ¡ disposto a investir?"
];

/**
 * ğŸ”„ Gera a rotina de atendimento com base no contexto e regras definidas
 */
const generateRoutine = async (userId, userInput) => {
    try {
        console.log(`ğŸ” Gerando rotina para usuÃ¡rio ${userId} com mensagem: ${userInput}`);

        // ğŸ“Œ ObtÃ©m a Ãºltima interaÃ§Ã£o do usuÃ¡rio
        const lastInteraction = await getLastInteraction(userId);
        const currentTime = Date.now();

        let userStage = await getUserStage(userId);
        console.log(`ğŸ“Œ O usuÃ¡rio ${userId} estÃ¡ no estÃ¡gio: ${userStage}`);

        // â³ Se a Ãºltima interaÃ§Ã£o foi hÃ¡ mais de 5 minutos, perguntar se deseja reiniciar
        if (lastInteraction && (currentTime - lastInteraction) > CHECK_TIME_LIMIT) {
            if (userInput.toLowerCase().includes("sim")) {
                console.log(`ğŸ”„ UsuÃ¡rio ${userId} optou por reiniciar o atendimento.`);
                
                await setUserStage(userId, RESET_STAGE);
                await redis.set(`survey_step:${userId}`, 0);
                await setLastInteraction(userId);

                await storeUserMessage(userId, "Anna: Atendimento reiniciado. Vamos comeÃ§ar com algumas perguntas.");
                return {
                    routine: "Atendimento reiniciado.",
                    response: SURVEY_QUESTIONS[0] // Envia a primeira pergunta
                };
            } else if (userInput.toLowerCase().includes("nÃ£o")) {
                console.log(`ğŸ”„ UsuÃ¡rio ${userId} escolheu continuar de onde parou.`);

                // ğŸ” Recupera o histÃ³rico de interaÃ§Ãµes do usuÃ¡rio
                const chatHistory = await getUserChatHistory(userId);
                const historyText = chatHistory.join("\n");

                // ğŸ” Identifica o estÃ¡gio do usuÃ¡rio baseado nas interaÃ§Ãµes
                let detectedStage = userStage;
                if (!detectedStage || detectedStage === "abordagem") {
                    detectedStage = getStageFromUserInput(historyText, "abordagem");
                    await setUserStage(userId, detectedStage);
                }

                console.log(`ğŸ“Œ Determinado estÃ¡gio do usuÃ¡rio: ${detectedStage}`);

                // ğŸ“¡ Gera perguntas personalizadas com base no histÃ³rico
                const userContext = `
                O cliente jÃ¡ interagiu anteriormente. Aqui estÃ¡ o histÃ³rico:
                ${historyText}
                
                Ele estÃ¡ atualmente na etapa de venda: ${detectedStage}.
                
                Gere uma pergunta emocional e envolvente para continuar o atendimento de forma natural. 
                A pergunta deve considerar o estÃ¡gio de venda e criar conexÃ£o emocional com o cliente.
                Use um tom humanizado, amigÃ¡vel e persuasivo.
                `;
                
                console.log("ğŸ“¡ Enviando requisiÃ§Ã£o Ã  OpenAI para gerar pergunta dinÃ¢mica...");
                const aiResponse = await openai.chat.completions.create({
                    model: "gpt-4-1106-preview",
                    messages: [{ role: "system", content: userContext }],
                    max_tokens: 300,
                });

                if (!aiResponse.choices || aiResponse.choices.length === 0 || !aiResponse.choices[0].message) {
                    console.error("âŒ Erro ao obter pergunta da OpenAI.");
                    return { routine: "Erro ao gerar pergunta personalizada.", response: "Desculpe, houve um problema ao continuar o atendimento." };
                }

                const finalQuestion = aiResponse.choices[0].message.content.trim();
                console.log("ğŸ’¬ Pergunta gerada pela OpenAI:", finalQuestion);

                await storeUserMessage(userId, `Anna: ${finalQuestion}`);
                await setLastInteraction(userId);

                return {
                    routine: `Continuando o atendimento na etapa ${detectedStage}.`,
                    response: finalQuestion
                };
            } else {
                return {
                    routine: "SessÃ£o expirada. Perguntar se deseja reiniciar.",
                    response: "Seu atendimento foi pausado. Deseja reiniciar o atendimento? Responda 'sim' para comeÃ§ar do zero ou 'nÃ£o' para continuar de onde parou."
                };
            }
        }

        // ğŸ”„ Determina o estÃ¡gio correto com base na entrada do usuÃ¡rio
        const detectedStage = getStageFromUserInput(userInput, userStage);

        if (detectedStage !== userStage) {
            userStage = await validateStageProgression(userId, detectedStage, userStage);
            await setUserStage(userId, userStage);
        }

        // ğŸš€ LÃ³gica para a etapa de "Sondagem de OrÃ§amento"
        if (userStage === "sondagem_de_orcamento") {
            let surveyStep = await redis.get(`survey_step:${userId}`);
            surveyStep = surveyStep ? parseInt(surveyStep, 10) : 0;

            // ğŸ”„ Armazena a resposta do usuÃ¡rio antes de avanÃ§ar
            await redis.set(`survey_response_${surveyStep}:${userId}`, userInput);
            await storeUserMessage(userId, `UsuÃ¡rio: ${userInput}`);

            surveyStep++; // AvanÃ§a para a prÃ³xima pergunta

            if (surveyStep < SURVEY_QUESTIONS.length) {
                await redis.set(`survey_step:${userId}`, surveyStep);
                await setLastInteraction(userId);
                return { routine: `Pergunta ${surveyStep} da sondagem`, response: SURVEY_QUESTIONS[surveyStep] };
            }

            // ğŸš€ Se todas as perguntas foram respondidas, avanÃ§a para demonstraÃ§Ã£o do produto
            await setUserStage(userId, "demonstracao_do_produto");
            await setLastInteraction(userId);

            console.log("âœ… Sondagem finalizada. Recuperando respostas para gerar um feedback humanizado...");

// ğŸ” Recupera as respostas do usuÃ¡rio armazenadas no Redis
const produtoDesejado = await redis.get(`survey_response_0:${userId}`) || "produto nÃ£o informado";
const necessidade = await redis.get(`survey_response_1:${userId}`) || "necessidade nÃ£o informada";
const investimento = await redis.get(`survey_response_2:${userId}`) || "orÃ§amento nÃ£o informado";

// ğŸ” ObtÃ©m o histÃ³rico completo do usuÃ¡rio para contexto adicional
const chatHistory = await getUserChatHistory(userId);
const historyText = chatHistory.join("\n");

// ğŸ“¡ Prepara o contexto para a OpenAI gerar uma resposta humanizada e envolvente
const userContext = `
O cliente mencionou que estÃ¡ interessado no seguinte produto: ${produtoDesejado}.
Ele precisa desse produto para: ${necessidade}.
O orÃ§amento disponÃ­vel Ã©: ${investimento}.

Aqui estÃ¡ o histÃ³rico de interaÃ§Ã£o com o cliente:
${historyText}

Com base nesses dados:
1ï¸âƒ£ Crie uma resposta envolvente e persuasiva, destacando os benefÃ­cios desse produto no dia a dia do cliente.
2ï¸âƒ£ Utilize um tom amigÃ¡vel, humanizado e que gere conexÃ£o emocional.
3ï¸âƒ£ Finalize com uma pergunta natural que incentive o cliente a continuar interagindo antes da demonstraÃ§Ã£o do produto.
`;

// ğŸ“¡ Chama a OpenAI para gerar a resposta personalizada
console.log("ğŸ“¡ Enviando requisiÃ§Ã£o Ã  OpenAI para gerar resposta personalizada...");
const aiResponse = await openai.chat.completions.create({
    model: "gpt-4-1106-preview",
    messages: [{ role: "system", content: userContext }],
    max_tokens: 500,
});

if (!aiResponse.choices || aiResponse.choices.length === 0 || !aiResponse.choices[0].message) {
    console.error("âŒ Erro ao obter resposta da OpenAI.");
    return { routine: "Erro ao gerar resposta personalizada.", response: "Desculpe, houve um problema ao processar sua solicitaÃ§Ã£o." };
}

const finalResponse = aiResponse.choices[0].message.content.trim();
console.log("ğŸ’¬ Resposta gerada pela OpenAI:", finalResponse);

// ğŸ”„ Armazena a resposta no histÃ³rico e responde ao cliente
await storeUserMessage(userId, `Anna: ${finalResponse}`);
await setLastInteraction(userId);

// ğŸš€ Agora sim, avanÃ§a para a demonstraÃ§Ã£o do produto
await setUserStage(userId, "demonstracao_do_produto");

return {
    routine: "Sondagem finalizada. Gerando feedback humanizado e indo para demonstraÃ§Ã£o do produto.",
    response: finalResponse
};
        }

        // ğŸ”„ ObtÃ©m resposta predefinida do estÃ¡gio atual
        let responseText = STAGE_RULES[userStage]?.response || "NÃ£o entendi sua solicitaÃ§Ã£o. Pode reformular?";

        await storeUserMessage(userId, `Anna: ${responseText}`);
        await setLastInteraction(userId);

        return { routine: `Rotina baseada no estÃ¡gio: ${userStage}`, response: responseText };

    } catch (error) {
        console.error(`âŒ Erro ao gerar rotina e resposta: ${error.message}`);
        return { routine: "Erro ao gerar a rotina de atendimento.", response: "Erro ao gerar a resposta ao usuÃ¡rio." };
    }
};

module.exports = { generateRoutine };
